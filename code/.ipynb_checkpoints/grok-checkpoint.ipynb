{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a2a0ecc-8d5c-435e-979b-a8fd4ab41b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\amanp\\\\Desktop\\\\MINOR\\\\projj\\\\code'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %cd code\n",
    "# insert your desired path to work on\n",
    "import os\n",
    "from os.path import join\n",
    "project_path = os.path.dirname(os.getcwd())\n",
    "# os.chdir(join('..','data'))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3275a8a0-08fd-4506-93ec-6f3697429bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(join(project_path, 'code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23108f5d-1db0-4d2c-8d8f-43f22d835dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f1723-9048-4626-b10b-fc41db40bb91",
   "metadata": {},
   "source": [
    "**Plots settings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5ece1c4-aeb7-4c1a-a4af-cfa17c3e6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'family':'Arial', 'size':'15', 'weight':'normal'}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3150481-e17e-4370-8af2-18d9ffad63e9",
   "metadata": {},
   "source": [
    "**Set folder structure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cd1f05b-d370-47fa-98d4-f21765bb837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'main_brazil': 'Brazil',\n",
    "    'main_peru': 'Peru',\n",
    "    'baseline': join(project_path, \"baseline_models\"),\n",
    "    'output': join(project_path, \"code\", \"saved_models\"),\n",
    "    'metrics': join(project_path, \"code\", \"metrics\")\n",
    "}\n",
    "project_path\n",
    "\n",
    "# List comprehension for the folder structure code\n",
    "[os.makedirs(val, exist_ok=True) for key, val in config.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d03a7-4e2c-43f7-8666-5a8b5a9dc4f2",
   "metadata": {},
   "source": [
    "# **AI4Dengue forecasting**\n",
    "![](https://drive.google.com/uc?export=view&id=1J5Bt5Cks-e2IV-dEJLHJkuwXFJNFAZgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7500c196-3865-46b4-9d8c-ecd6fcdfa4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from config import DEP_NAMES, GROUPED_VARS, DATA_REDUCER_SETTINGS, DATA_PROCESSING_SETTINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e51c1662-2091-4a04-a30c-25e8c463984e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'clean',\n",
       " 'cx',\n",
       " 'geopandas',\n",
       " 'pd',\n",
       " 'plist',\n",
       " 'plotShape']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6759d5-edb1-4bac-902b-c8ac0eb1f871",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7c0aa-55f6-4e3b-944c-f7252c767781",
   "metadata": {},
   "source": [
    "## Load the dataframe\n",
    "**This dataframe comprises all the variables (climatic, epidemiological etc.) acquired for each Department during a defined number of years.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4d01198-5be6-4b49-8847-5eb5000b5365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                2004-02-01\n",
       "Year                      2004\n",
       "Month                        2\n",
       "CD_UF                       12\n",
       "area_km2            164173.431\n",
       "                       ...    \n",
       "rdpc_def_vulner         119.68\n",
       "t_analf_18m              17.79\n",
       "t_formal_18m             46.45\n",
       "t_fundc_ocup18m           55.2\n",
       "t_medioc_ocup18m         39.61\n",
       "Name: 1000, Length: 62, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(join('dataset', \"Brazil_UF_dengue_monthly.csv\"))\n",
    "dataframe.head()\n",
    "dataframe.iloc[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c3d91-97f3-4ed8-bb3b-6c5af36f1c4b",
   "metadata": {},
   "source": [
    "**Load CNN results as columns to dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "226baa71-8386-4733-8378-47be7c78124c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_UF</th>\n",
       "      <th>CNN_all</th>\n",
       "      <th>CNN_0-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>32.159859</td>\n",
       "      <td>17.186546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>53</td>\n",
       "      <td>29.022461</td>\n",
       "      <td>16.795465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>53</td>\n",
       "      <td>20.277210</td>\n",
       "      <td>5.658783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>53</td>\n",
       "      <td>7.219064</td>\n",
       "      <td>16.862005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>53</td>\n",
       "      <td>17.866333</td>\n",
       "      <td>28.619926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>53</td>\n",
       "      <td>13.846931</td>\n",
       "      <td>8.825871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CD_UF    CNN_all   CNN_0-19\n",
       "0        11   1.000000   1.000000\n",
       "1        11   1.000000   1.000000\n",
       "2        11   1.000000   1.000000\n",
       "3        11   1.000000   1.000000\n",
       "4        11  32.159859  17.186546\n",
       "...     ...        ...        ...\n",
       "6151     53  29.022461  16.795465\n",
       "6152     53  20.277210   5.658783\n",
       "6153     53   7.219064  16.862005\n",
       "6154     53  17.866333  28.619926\n",
       "6155     53  13.846931   8.825871\n",
       "\n",
       "[6156 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = pd.read_csv(join('saved_models', \"cnn_dataframe.csv\")).drop('Unnamed: 0', axis=1)\n",
    "cnn['CD_UF'] = cnn['CD_UF'].astype(np.int64)\n",
    "\n",
    "assert dataframe.shape[0] == cnn.shape[0]\n",
    "assert all(dataframe['CD_UF'].unique() == cnn['CD_UF'].unique())\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7058840e-9ee5-4b2b-9fa7-2448b9d324a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>CD_UF</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>NDVI_d</th>\n",
       "      <th>dewpoint_temperature_2m_d</th>\n",
       "      <th>humidity_d</th>\n",
       "      <th>max_temperature_2m_d</th>\n",
       "      <th>min_temperature_2m_d</th>\n",
       "      <th>...</th>\n",
       "      <th>pea10a14</th>\n",
       "      <th>pea15a17</th>\n",
       "      <th>pea18m</th>\n",
       "      <th>t_eletrica</th>\n",
       "      <th>t_densidadem2</th>\n",
       "      <th>rdpc_def_vulner</th>\n",
       "      <th>t_analf_18m</th>\n",
       "      <th>t_formal_18m</th>\n",
       "      <th>t_fundc_ocup18m</th>\n",
       "      <th>t_medioc_ocup18m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.154301</td>\n",
       "      <td>295.674980</td>\n",
       "      <td>88.460308</td>\n",
       "      <td>303.987216</td>\n",
       "      <td>294.155015</td>\n",
       "      <td>...</td>\n",
       "      <td>18698</td>\n",
       "      <td>34904</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.216873</td>\n",
       "      <td>295.944060</td>\n",
       "      <td>88.856948</td>\n",
       "      <td>304.738755</td>\n",
       "      <td>294.332566</td>\n",
       "      <td>...</td>\n",
       "      <td>18698</td>\n",
       "      <td>34904</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-03-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.239112</td>\n",
       "      <td>296.092747</td>\n",
       "      <td>89.305463</td>\n",
       "      <td>304.620829</td>\n",
       "      <td>294.304126</td>\n",
       "      <td>...</td>\n",
       "      <td>18698</td>\n",
       "      <td>34904</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.334660</td>\n",
       "      <td>296.186143</td>\n",
       "      <td>88.590375</td>\n",
       "      <td>304.168669</td>\n",
       "      <td>293.921815</td>\n",
       "      <td>...</td>\n",
       "      <td>18698</td>\n",
       "      <td>34904</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.378931</td>\n",
       "      <td>295.562972</td>\n",
       "      <td>86.939606</td>\n",
       "      <td>303.903043</td>\n",
       "      <td>293.395959</td>\n",
       "      <td>...</td>\n",
       "      <td>18698</td>\n",
       "      <td>34904</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.362744</td>\n",
       "      <td>282.150351</td>\n",
       "      <td>42.202163</td>\n",
       "      <td>304.210083</td>\n",
       "      <td>287.271135</td>\n",
       "      <td>...</td>\n",
       "      <td>10706</td>\n",
       "      <td>36652</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.317748</td>\n",
       "      <td>281.820936</td>\n",
       "      <td>34.023500</td>\n",
       "      <td>307.566780</td>\n",
       "      <td>290.719267</td>\n",
       "      <td>...</td>\n",
       "      <td>10706</td>\n",
       "      <td>36652</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.271795</td>\n",
       "      <td>286.196146</td>\n",
       "      <td>45.486547</td>\n",
       "      <td>307.716003</td>\n",
       "      <td>291.720099</td>\n",
       "      <td>...</td>\n",
       "      <td>10706</td>\n",
       "      <td>36652</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.235493</td>\n",
       "      <td>290.445969</td>\n",
       "      <td>64.916154</td>\n",
       "      <td>306.706715</td>\n",
       "      <td>291.496597</td>\n",
       "      <td>...</td>\n",
       "      <td>10706</td>\n",
       "      <td>36652</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.314533</td>\n",
       "      <td>291.019027</td>\n",
       "      <td>69.799133</td>\n",
       "      <td>303.716225</td>\n",
       "      <td>291.647991</td>\n",
       "      <td>...</td>\n",
       "      <td>10706</td>\n",
       "      <td>36652</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6156 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Year  Month  CD_UF    area_km2    NDVI_d  \\\n",
       "0     2001-01-01  2001      1     11  237765.347  0.154301   \n",
       "1     2001-02-01  2001      2     11  237765.347  0.216873   \n",
       "2     2001-03-01  2001      3     11  237765.347  0.239112   \n",
       "3     2001-04-01  2001      4     11  237765.347  0.334660   \n",
       "4     2001-05-01  2001      5     11  237765.347  0.378931   \n",
       "...          ...   ...    ...    ...         ...       ...   \n",
       "6151  2019-08-01  2019      8     53    5760.784  0.362744   \n",
       "6152  2019-09-01  2019      9     53    5760.784  0.317748   \n",
       "6153  2019-10-01  2019     10     53    5760.784  0.271795   \n",
       "6154  2019-11-01  2019     11     53    5760.784  0.235493   \n",
       "6155  2019-12-01  2019     12     53    5760.784  0.314533   \n",
       "\n",
       "      dewpoint_temperature_2m_d  humidity_d  max_temperature_2m_d  \\\n",
       "0                    295.674980   88.460308            303.987216   \n",
       "1                    295.944060   88.856948            304.738755   \n",
       "2                    296.092747   89.305463            304.620829   \n",
       "3                    296.186143   88.590375            304.168669   \n",
       "4                    295.562972   86.939606            303.903043   \n",
       "...                         ...         ...                   ...   \n",
       "6151                 282.150351   42.202163            304.210083   \n",
       "6152                 281.820936   34.023500            307.566780   \n",
       "6153                 286.196146   45.486547            307.716003   \n",
       "6154                 290.445969   64.916154            306.706715   \n",
       "6155                 291.019027   69.799133            303.716225   \n",
       "\n",
       "      min_temperature_2m_d  ...  pea10a14  pea15a17   pea18m  t_eletrica  \\\n",
       "0               294.155015  ...     18698     34904   723839       97.26   \n",
       "1               294.332566  ...     18698     34904   723839       97.26   \n",
       "2               294.304126  ...     18698     34904   723839       97.26   \n",
       "3               293.921815  ...     18698     34904   723839       97.26   \n",
       "4               293.395959  ...     18698     34904   723839       97.26   \n",
       "...                    ...  ...       ...       ...      ...         ...   \n",
       "6151            287.271135  ...     10706     36652  1361053       99.91   \n",
       "6152            290.719267  ...     10706     36652  1361053       99.91   \n",
       "6153            291.720099  ...     10706     36652  1361053       99.91   \n",
       "6154            291.496597  ...     10706     36652  1361053       99.91   \n",
       "6155            291.647991  ...     10706     36652  1361053       99.91   \n",
       "\n",
       "      t_densidadem2  rdpc_def_vulner  t_analf_18m  t_formal_18m  \\\n",
       "0             27.15           144.93         9.42         51.72   \n",
       "1             27.15           144.93         9.42         51.72   \n",
       "2             27.15           144.93         9.42         51.72   \n",
       "3             27.15           144.93         9.42         51.72   \n",
       "4             27.15           144.93         9.42         51.72   \n",
       "...             ...              ...          ...           ...   \n",
       "6151          23.48           171.62         3.66         71.62   \n",
       "6152          23.48           171.62         3.66         71.62   \n",
       "6153          23.48           171.62         3.66         71.62   \n",
       "6154          23.48           171.62         3.66         71.62   \n",
       "6155          23.48           171.62         3.66         71.62   \n",
       "\n",
       "      t_fundc_ocup18m  t_medioc_ocup18m  \n",
       "0               53.83             36.93  \n",
       "1               53.83             36.93  \n",
       "2               53.83             36.93  \n",
       "3               53.83             36.93  \n",
       "4               53.83             36.93  \n",
       "...               ...               ...  \n",
       "6151            76.39             61.00  \n",
       "6152            76.39             61.00  \n",
       "6153            76.39             61.00  \n",
       "6154            76.39             61.00  \n",
       "6155            76.39             61.00  \n",
       "\n",
       "[6156 rows x 62 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.sort_values(['CD_UF', 'Date'], inplace=True, ignore_index=True)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63aa9819-18cd-45b0-bd26-e3a02df33b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>CD_UF</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>NDVI_d</th>\n",
       "      <th>dewpoint_temperature_2m_d</th>\n",
       "      <th>humidity_d</th>\n",
       "      <th>max_temperature_2m_d</th>\n",
       "      <th>min_temperature_2m_d</th>\n",
       "      <th>...</th>\n",
       "      <th>pea18m</th>\n",
       "      <th>t_eletrica</th>\n",
       "      <th>t_densidadem2</th>\n",
       "      <th>rdpc_def_vulner</th>\n",
       "      <th>t_analf_18m</th>\n",
       "      <th>t_formal_18m</th>\n",
       "      <th>t_fundc_ocup18m</th>\n",
       "      <th>t_medioc_ocup18m</th>\n",
       "      <th>CNN_all</th>\n",
       "      <th>CNN_0-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.154301</td>\n",
       "      <td>295.674980</td>\n",
       "      <td>88.460308</td>\n",
       "      <td>303.987216</td>\n",
       "      <td>294.155015</td>\n",
       "      <td>...</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.216873</td>\n",
       "      <td>295.944060</td>\n",
       "      <td>88.856948</td>\n",
       "      <td>304.738755</td>\n",
       "      <td>294.332566</td>\n",
       "      <td>...</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-03-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.239112</td>\n",
       "      <td>296.092747</td>\n",
       "      <td>89.305463</td>\n",
       "      <td>304.620829</td>\n",
       "      <td>294.304126</td>\n",
       "      <td>...</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.334660</td>\n",
       "      <td>296.186143</td>\n",
       "      <td>88.590375</td>\n",
       "      <td>304.168669</td>\n",
       "      <td>293.921815</td>\n",
       "      <td>...</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.378931</td>\n",
       "      <td>295.562972</td>\n",
       "      <td>86.939606</td>\n",
       "      <td>303.903043</td>\n",
       "      <td>293.395959</td>\n",
       "      <td>...</td>\n",
       "      <td>723839</td>\n",
       "      <td>97.26</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>32.159859</td>\n",
       "      <td>17.186546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.362744</td>\n",
       "      <td>282.150351</td>\n",
       "      <td>42.202163</td>\n",
       "      <td>304.210083</td>\n",
       "      <td>287.271135</td>\n",
       "      <td>...</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "      <td>29.022461</td>\n",
       "      <td>16.795465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.317748</td>\n",
       "      <td>281.820936</td>\n",
       "      <td>34.023500</td>\n",
       "      <td>307.566780</td>\n",
       "      <td>290.719267</td>\n",
       "      <td>...</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "      <td>20.277210</td>\n",
       "      <td>5.658783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.271795</td>\n",
       "      <td>286.196146</td>\n",
       "      <td>45.486547</td>\n",
       "      <td>307.716003</td>\n",
       "      <td>291.720099</td>\n",
       "      <td>...</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "      <td>7.219064</td>\n",
       "      <td>16.862005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.235493</td>\n",
       "      <td>290.445969</td>\n",
       "      <td>64.916154</td>\n",
       "      <td>306.706715</td>\n",
       "      <td>291.496597</td>\n",
       "      <td>...</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "      <td>17.866333</td>\n",
       "      <td>28.619926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>5760.784</td>\n",
       "      <td>0.314533</td>\n",
       "      <td>291.019027</td>\n",
       "      <td>69.799133</td>\n",
       "      <td>303.716225</td>\n",
       "      <td>291.647991</td>\n",
       "      <td>...</td>\n",
       "      <td>1361053</td>\n",
       "      <td>99.91</td>\n",
       "      <td>23.48</td>\n",
       "      <td>171.62</td>\n",
       "      <td>3.66</td>\n",
       "      <td>71.62</td>\n",
       "      <td>76.39</td>\n",
       "      <td>61.00</td>\n",
       "      <td>13.846931</td>\n",
       "      <td>8.825871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6156 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Year  Month  CD_UF    area_km2    NDVI_d  \\\n",
       "0     2001-01-01  2001      1     11  237765.347  0.154301   \n",
       "1     2001-02-01  2001      2     11  237765.347  0.216873   \n",
       "2     2001-03-01  2001      3     11  237765.347  0.239112   \n",
       "3     2001-04-01  2001      4     11  237765.347  0.334660   \n",
       "4     2001-05-01  2001      5     11  237765.347  0.378931   \n",
       "...          ...   ...    ...    ...         ...       ...   \n",
       "6151  2019-08-01  2019      8     53    5760.784  0.362744   \n",
       "6152  2019-09-01  2019      9     53    5760.784  0.317748   \n",
       "6153  2019-10-01  2019     10     53    5760.784  0.271795   \n",
       "6154  2019-11-01  2019     11     53    5760.784  0.235493   \n",
       "6155  2019-12-01  2019     12     53    5760.784  0.314533   \n",
       "\n",
       "      dewpoint_temperature_2m_d  humidity_d  max_temperature_2m_d  \\\n",
       "0                    295.674980   88.460308            303.987216   \n",
       "1                    295.944060   88.856948            304.738755   \n",
       "2                    296.092747   89.305463            304.620829   \n",
       "3                    296.186143   88.590375            304.168669   \n",
       "4                    295.562972   86.939606            303.903043   \n",
       "...                         ...         ...                   ...   \n",
       "6151                 282.150351   42.202163            304.210083   \n",
       "6152                 281.820936   34.023500            307.566780   \n",
       "6153                 286.196146   45.486547            307.716003   \n",
       "6154                 290.445969   64.916154            306.706715   \n",
       "6155                 291.019027   69.799133            303.716225   \n",
       "\n",
       "      min_temperature_2m_d  ...   pea18m  t_eletrica  t_densidadem2  \\\n",
       "0               294.155015  ...   723839       97.26          27.15   \n",
       "1               294.332566  ...   723839       97.26          27.15   \n",
       "2               294.304126  ...   723839       97.26          27.15   \n",
       "3               293.921815  ...   723839       97.26          27.15   \n",
       "4               293.395959  ...   723839       97.26          27.15   \n",
       "...                    ...  ...      ...         ...            ...   \n",
       "6151            287.271135  ...  1361053       99.91          23.48   \n",
       "6152            290.719267  ...  1361053       99.91          23.48   \n",
       "6153            291.720099  ...  1361053       99.91          23.48   \n",
       "6154            291.496597  ...  1361053       99.91          23.48   \n",
       "6155            291.647991  ...  1361053       99.91          23.48   \n",
       "\n",
       "      rdpc_def_vulner  t_analf_18m  t_formal_18m  t_fundc_ocup18m  \\\n",
       "0              144.93         9.42         51.72            53.83   \n",
       "1              144.93         9.42         51.72            53.83   \n",
       "2              144.93         9.42         51.72            53.83   \n",
       "3              144.93         9.42         51.72            53.83   \n",
       "4              144.93         9.42         51.72            53.83   \n",
       "...               ...          ...           ...              ...   \n",
       "6151           171.62         3.66         71.62            76.39   \n",
       "6152           171.62         3.66         71.62            76.39   \n",
       "6153           171.62         3.66         71.62            76.39   \n",
       "6154           171.62         3.66         71.62            76.39   \n",
       "6155           171.62         3.66         71.62            76.39   \n",
       "\n",
       "      t_medioc_ocup18m    CNN_all   CNN_0-19  \n",
       "0                36.93   1.000000   1.000000  \n",
       "1                36.93   1.000000   1.000000  \n",
       "2                36.93   1.000000   1.000000  \n",
       "3                36.93   1.000000   1.000000  \n",
       "4                36.93  32.159859  17.186546  \n",
       "...                ...        ...        ...  \n",
       "6151             61.00  29.022461  16.795465  \n",
       "6152             61.00  20.277210   5.658783  \n",
       "6153             61.00   7.219064  16.862005  \n",
       "6154             61.00  17.866333  28.619926  \n",
       "6155             61.00  13.846931   8.825871  \n",
       "\n",
       "[6156 rows x 64 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.concat([dataframe, cnn[['CNN_all', 'CNN_0-19']]], axis=1)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9066fd-2cd7-4eec-992b-a5a71c15eb64",
   "metadata": {},
   "source": [
    "**'Clean' the dataset (e.g. remove NaN values)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3460e348-b7ef-4fb4-942f-0ce0feae1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataframe...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>CD_UF</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>NDVI_d</th>\n",
       "      <th>dewpoint_temperature_2m_d</th>\n",
       "      <th>humidity_d</th>\n",
       "      <th>max_temperature_2m_d</th>\n",
       "      <th>min_temperature_2m_d</th>\n",
       "      <th>...</th>\n",
       "      <th>t_densidadem2</th>\n",
       "      <th>rdpc_def_vulner</th>\n",
       "      <th>t_analf_18m</th>\n",
       "      <th>t_formal_18m</th>\n",
       "      <th>t_fundc_ocup18m</th>\n",
       "      <th>t_medioc_ocup18m</th>\n",
       "      <th>CNN_all</th>\n",
       "      <th>CNN_0-19</th>\n",
       "      <th>rate_total</th>\n",
       "      <th>rate_019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.154301</td>\n",
       "      <td>295.674980</td>\n",
       "      <td>88.460308</td>\n",
       "      <td>303.987216</td>\n",
       "      <td>294.155015</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.754490</td>\n",
       "      <td>29.124122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.216873</td>\n",
       "      <td>295.944060</td>\n",
       "      <td>88.856948</td>\n",
       "      <td>304.738755</td>\n",
       "      <td>294.332566</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.601025</td>\n",
       "      <td>11.718582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-03-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.239112</td>\n",
       "      <td>296.092747</td>\n",
       "      <td>89.305463</td>\n",
       "      <td>304.620829</td>\n",
       "      <td>294.304126</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.072645</td>\n",
       "      <td>6.376287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.334660</td>\n",
       "      <td>296.186143</td>\n",
       "      <td>88.590375</td>\n",
       "      <td>304.168669</td>\n",
       "      <td>293.921815</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.120298</td>\n",
       "      <td>3.791306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>237765.347</td>\n",
       "      <td>0.378931</td>\n",
       "      <td>295.562972</td>\n",
       "      <td>86.939606</td>\n",
       "      <td>303.903043</td>\n",
       "      <td>293.395959</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>144.93</td>\n",
       "      <td>9.42</td>\n",
       "      <td>51.72</td>\n",
       "      <td>53.83</td>\n",
       "      <td>36.93</td>\n",
       "      <td>32.159859</td>\n",
       "      <td>17.186546</td>\n",
       "      <td>6.976406</td>\n",
       "      <td>4.652966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Year  Month  CD_UF    area_km2    NDVI_d  \\\n",
       "0  2001-01-01  2001      1     11  237765.347  0.154301   \n",
       "1  2001-02-01  2001      2     11  237765.347  0.216873   \n",
       "2  2001-03-01  2001      3     11  237765.347  0.239112   \n",
       "3  2001-04-01  2001      4     11  237765.347  0.334660   \n",
       "4  2001-05-01  2001      5     11  237765.347  0.378931   \n",
       "\n",
       "   dewpoint_temperature_2m_d  humidity_d  max_temperature_2m_d  \\\n",
       "0                 295.674980   88.460308            303.987216   \n",
       "1                 295.944060   88.856948            304.738755   \n",
       "2                 296.092747   89.305463            304.620829   \n",
       "3                 296.186143   88.590375            304.168669   \n",
       "4                 295.562972   86.939606            303.903043   \n",
       "\n",
       "   min_temperature_2m_d  ...  t_densidadem2  rdpc_def_vulner  t_analf_18m  \\\n",
       "0            294.155015  ...          27.15           144.93         9.42   \n",
       "1            294.332566  ...          27.15           144.93         9.42   \n",
       "2            294.304126  ...          27.15           144.93         9.42   \n",
       "3            293.921815  ...          27.15           144.93         9.42   \n",
       "4            293.395959  ...          27.15           144.93         9.42   \n",
       "\n",
       "   t_formal_18m  t_fundc_ocup18m  t_medioc_ocup18m    CNN_all   CNN_0-19  \\\n",
       "0         51.72            53.83             36.93   1.000000   1.000000   \n",
       "1         51.72            53.83             36.93   1.000000   1.000000   \n",
       "2         51.72            53.83             36.93   1.000000   1.000000   \n",
       "3         51.72            53.83             36.93   1.000000   1.000000   \n",
       "4         51.72            53.83             36.93  32.159859  17.186546   \n",
       "\n",
       "   rate_total   rate_019  \n",
       "0   42.754490  29.124122  \n",
       "1   17.601025  11.718582  \n",
       "2   11.072645   6.376287  \n",
       "3    5.120298   3.791306  \n",
       "4    6.976406   4.652966  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = utils.clean(dataframe)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ced689e-84ae-4d4b-b201-fa70bbb7fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6156 entries, 0 to 6155\n",
      "Data columns (total 61 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Date                       6156 non-null   object \n",
      " 1   Year                       6156 non-null   int64  \n",
      " 2   Month                      6156 non-null   int64  \n",
      " 3   CD_UF                      6156 non-null   int64  \n",
      " 4   area_km2                   6156 non-null   float64\n",
      " 5   NDVI_d                     6156 non-null   float64\n",
      " 6   dewpoint_temperature_2m_d  6156 non-null   float64\n",
      " 7   humidity_d                 6156 non-null   float64\n",
      " 8   max_temperature_2m_d       6156 non-null   float64\n",
      " 9   min_temperature_2m_d       6156 non-null   float64\n",
      " 10  surface_pressure_d         6156 non-null   float64\n",
      " 11  temperature_2m_d           6156 non-null   float64\n",
      " 12  total_precipitation_d      6156 non-null   float64\n",
      " 13  u_component_of_wind_10m_d  6156 non-null   float64\n",
      " 14  v_component_of_wind_10m_d  6156 non-null   float64\n",
      " 15  max_elevation_d            6156 non-null   float64\n",
      " 16  mean_elevation_d           6156 non-null   float64\n",
      " 17  min_elevation_d            6156 non-null   float64\n",
      " 18  stdDev_elevation_d         6156 non-null   float64\n",
      " 19  variance_elevation_d       6156 non-null   float64\n",
      " 20  PopTotal_Urban_UF          6156 non-null   int64  \n",
      " 21  PopTotal_Rural_UF          6156 non-null   int64  \n",
      " 22  cases0_19                  6156 non-null   int64  \n",
      " 23  cases20_99                 6156 non-null   int64  \n",
      " 24  Forest_Cover_Percent       6156 non-null   float64\n",
      " 25  Urban_Cover_Percent        6156 non-null   float64\n",
      " 26  ivs                        6156 non-null   float64\n",
      " 27  ivs_infraestrutura_urbana  6156 non-null   float64\n",
      " 28  ivs_capital_humano         6156 non-null   float64\n",
      " 29  ivs_renda_e_trabalho       6156 non-null   float64\n",
      " 30  t_sem_agua_esgoto          6156 non-null   float64\n",
      " 31  t_sem_lixo                 6156 non-null   float64\n",
      " 32  t_vulner_mais1h            6156 non-null   float64\n",
      " 33  t_analf_15m                6156 non-null   float64\n",
      " 34  t_cdom_fundin              6156 non-null   float64\n",
      " 35  t_p15a24_nada              6156 non-null   float64\n",
      " 36  t_vulner                   6156 non-null   float64\n",
      " 37  t_desocup18m               6156 non-null   float64\n",
      " 38  t_p18m_fundin_informal     6156 non-null   float64\n",
      " 39  idhm                       6156 non-null   float64\n",
      " 40  idhm_long                  6156 non-null   float64\n",
      " 41  idhm_educ                  6156 non-null   float64\n",
      " 42  idhm_renda                 6156 non-null   float64\n",
      " 43  idhm_educ_sub_esc          6156 non-null   float64\n",
      " 44  t_pop18m_fundc             6156 non-null   float64\n",
      " 45  idhm_educ_sub_freq         6156 non-null   float64\n",
      " 46  renda_per_capita           6156 non-null   float64\n",
      " 47  pea10a14                   6156 non-null   int64  \n",
      " 48  pea15a17                   6156 non-null   int64  \n",
      " 49  pea18m                     6156 non-null   int64  \n",
      " 50  t_eletrica                 6156 non-null   float64\n",
      " 51  t_densidadem2              6156 non-null   float64\n",
      " 52  rdpc_def_vulner            6156 non-null   float64\n",
      " 53  t_analf_18m                6156 non-null   float64\n",
      " 54  t_formal_18m               6156 non-null   float64\n",
      " 55  t_fundc_ocup18m            6156 non-null   float64\n",
      " 56  t_medioc_ocup18m           6156 non-null   float64\n",
      " 57  CNN_all                    6156 non-null   float64\n",
      " 58  CNN_0-19                   6156 non-null   float64\n",
      " 59  rate_total                 6156 non-null   float64\n",
      " 60  rate_019                   6156 non-null   float64\n",
      "dtypes: float64(50), int64(10), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65222af8-7c09-41d3-91ef-3ba56733fa12",
   "metadata": {},
   "source": [
    "## Apply Data Reduction\n",
    "**Data reduction is applied to three macro groups in order to reduce the number of variables on which the AI framework will be trained. The variables belonging to each group are set with the *PCAgroups* dictionary. The groups are:**\n",
    "1. ***CLIMATIC VARIABLES***,\n",
    "2. ***GEO VARIABLES***,\n",
    "3. ***SOCIO VARIABLES***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e9f63f3-50ef-45b7-8afa-c0ffd886b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m PCA Excluded Variables \u001b[0m\n",
      "----- 1 t_fundc_ocup18m\n",
      "----- 2 t_medioc_ocup18m\n",
      "----- 3 PopTotal_Urban_UF\n",
      "----- 4 PopTotal_Rural_UF\n",
      "----- 5 total_precipitation_d\n",
      "----- 6 surface_pressure_d\n",
      "----- 7 area_km2\n",
      "----- 8 humidity_d\n",
      "----- 9 temperature_2m_d\n",
      "----- 10 min_temperature_2m_d\n",
      "----- 11 CNN_all\n",
      "----- 12 CNN_0-19\n",
      "\u001b[1m Climatic variables \u001b[0m\n",
      "----- 1 dewpoint_temperature_2m_d\n",
      "----- 2 max_temperature_2m_d\n",
      "----- 3 u_component_of_wind_10m_d\n",
      "----- 4 v_component_of_wind_10m_d\n",
      "\u001b[1m Geo variables \u001b[0m\n",
      "----- 1 NDVI_d\n",
      "----- 2 max_elevation_d\n",
      "----- 3 mean_elevation_d\n",
      "----- 4 min_elevation_d\n",
      "----- 5 stdDev_elevation_d\n",
      "----- 6 variance_elevation_d\n",
      "----- 7 Forest_Cover_Percent\n",
      "----- 8 Urban_Cover_Percent\n",
      "\u001b[1m Socio variables \u001b[0m\n",
      "----- 1 Urban_Cover_Percent\n",
      "----- 2 ivs\n",
      "----- 3 ivs_infraestrutura_urbana\n",
      "----- 4 ivs_capital_humano\n",
      "----- 5 ivs_renda_e_trabalho\n",
      "----- 6 t_sem_agua_esgoto\n",
      "----- 7 t_sem_lixo\n",
      "----- 8 t_vulner_mais1h\n",
      "----- 9 t_analf_15m\n",
      "----- 10 t_cdom_fundin\n",
      "----- 11 t_p15a24_nada\n",
      "----- 12 t_vulner\n",
      "----- 13 t_desocup18m\n",
      "----- 14 t_p18m_fundin_informal\n",
      "----- 15 idhm\n",
      "----- 16 idhm_long\n",
      "----- 17 idhm_educ\n",
      "----- 18 idhm_renda\n",
      "----- 19 idhm_educ_sub_esc\n",
      "----- 20 t_pop18m_fundc\n",
      "----- 21 idhm_educ_sub_freq\n",
      "----- 22 renda_per_capita\n",
      "----- 23 pea10a14\n",
      "----- 24 pea15a17\n",
      "----- 25 pea18m\n",
      "----- 26 t_eletrica\n",
      "----- 27 t_densidadem2\n",
      "----- 28 rdpc_def_vulner\n",
      "----- 29 t_analf_18m\n",
      "----- 30 t_formal_18m\n",
      "\u001b[1m Additional variables \u001b[0m\n",
      "----- 1 Month\n",
      "----- 2 cases20_99\n",
      "----- 3 cases0_19\n",
      "\u001b[1m Dengue variables \u001b[0m\n",
      "----- 1 rate_total\n",
      "----- 2 rate_019\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m PCA Excluded Variables \\033[0m')\n",
    "utils.plist(GROUPED_VARS['EXCLUDED'])\n",
    "\n",
    "print('\\033[1m Climatic variables \\033[0m')\n",
    "utils.plist(GROUPED_VARS['CLIMATIC VARIABLES'])\n",
    "\n",
    "print('\\033[1m Geo variables \\033[0m')\n",
    "utils.plist(GROUPED_VARS['GEO VARIABLES'])\n",
    "\n",
    "print('\\033[1m Socio variables \\033[0m')\n",
    "utils.plist(GROUPED_VARS['SOCIO VARIABLES'])\n",
    "\n",
    "print('\\033[1m Additional variables \\033[0m')\n",
    "utils.plist(GROUPED_VARS['AUXILIAR'])\n",
    "\n",
    "print('\\033[1m Dengue variables \\033[0m')\n",
    "utils.plist(GROUPED_VARS['DENGUE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b59c62-94f7-4911-b89b-0360bcf6c3b0",
   "metadata": {},
   "source": [
    "**We selected two types of data reduction methods: PCA (Principal Component Analysis) and PLS (Principal Least Square). The second one is the default solution because it reduces the input data by considering also a second variable that in our case is the Dengue Incidence Rates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3e29a07-19cc-4ac1-a2ed-f94a196bb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reduction import pca_reducer, pls_reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "268483f9-aafe-4d69-9b8a-a8e042732cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Year', 'Month', 'CD_UF', 'area_km2', 'NDVI_d',\n",
      "       'dewpoint_temperature_2m_d', 'humidity_d', 'max_temperature_2m_d',\n",
      "       'min_temperature_2m_d', 'surface_pressure_d', 'temperature_2m_d',\n",
      "       'total_precipitation_d', 'u_component_of_wind_10m_d',\n",
      "       'v_component_of_wind_10m_d', 'max_elevation_d', 'mean_elevation_d',\n",
      "       'min_elevation_d', 'stdDev_elevation_d', 'variance_elevation_d',\n",
      "       'PopTotal_Urban_UF', 'PopTotal_Rural_UF', 'cases0_19', 'cases20_99',\n",
      "       'Forest_Cover_Percent', 'Urban_Cover_Percent', 'ivs',\n",
      "       'ivs_infraestrutura_urbana', 'ivs_capital_humano',\n",
      "       'ivs_renda_e_trabalho', 't_sem_agua_esgoto', 't_sem_lixo',\n",
      "       't_vulner_mais1h', 't_analf_15m', 't_cdom_fundin', 't_p15a24_nada',\n",
      "       't_vulner', 't_desocup18m', 't_p18m_fundin_informal', 'idhm',\n",
      "       'idhm_long', 'idhm_educ', 'idhm_renda', 'idhm_educ_sub_esc',\n",
      "       't_pop18m_fundc', 'idhm_educ_sub_freq', 'renda_per_capita', 'pea10a14',\n",
      "       'pea15a17', 'pea18m', 't_eletrica', 't_densidadem2', 'rdpc_def_vulner',\n",
      "       't_analf_18m', 't_formal_18m', 't_fundc_ocup18m', 't_medioc_ocup18m',\n",
      "       'CNN_all', 'CNN_0-19', 'rate_total', 'rate_019'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d4723-d30e-43b3-850c-dab6f4d3873e",
   "metadata": {},
   "source": [
    "**Extract climatic, geophysical and socio-economic variables from the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14ffb024-97ea-49dd-8454-0c58df3affd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_climatic = scaler.fit_transform(dataframe[GROUPED_VARS['CLIMATIC VARIABLES']].values)\n",
    "X_geo = scaler.fit_transform(dataframe[GROUPED_VARS['GEO VARIABLES']].values)\n",
    "X_socio = scaler.fit_transform(dataframe[GROUPED_VARS['SOCIO VARIABLES']].values)\n",
    "y_dengue = dataframe[GROUPED_VARS['DENGUE']].values  # Keep y_dengue unscaled for no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b8e21ed-e70d-4cf2-8d32-04b25fc38395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Year', 'Month', 'CD_UF', 'area_km2', 'NDVI_d',\n",
      "       'dewpoint_temperature_2m_d', 'humidity_d', 'max_temperature_2m_d',\n",
      "       'min_temperature_2m_d', 'surface_pressure_d', 'temperature_2m_d',\n",
      "       'total_precipitation_d', 'u_component_of_wind_10m_d',\n",
      "       'v_component_of_wind_10m_d', 'max_elevation_d', 'mean_elevation_d',\n",
      "       'min_elevation_d', 'stdDev_elevation_d', 'variance_elevation_d',\n",
      "       'PopTotal_Urban_UF', 'PopTotal_Rural_UF', 'cases0_19', 'cases20_99',\n",
      "       'Forest_Cover_Percent', 'Urban_Cover_Percent', 'ivs',\n",
      "       'ivs_infraestrutura_urbana', 'ivs_capital_humano',\n",
      "       'ivs_renda_e_trabalho', 't_sem_agua_esgoto', 't_sem_lixo',\n",
      "       't_vulner_mais1h', 't_analf_15m', 't_cdom_fundin', 't_p15a24_nada',\n",
      "       't_vulner', 't_desocup18m', 't_p18m_fundin_informal', 'idhm',\n",
      "       'idhm_long', 'idhm_educ', 'idhm_renda', 'idhm_educ_sub_esc',\n",
      "       't_pop18m_fundc', 'idhm_educ_sub_freq', 'renda_per_capita', 'pea10a14',\n",
      "       'pea15a17', 'pea18m', 't_eletrica', 't_densidadem2', 'rdpc_def_vulner',\n",
      "       't_analf_18m', 't_formal_18m', 't_fundc_ocup18m', 't_medioc_ocup18m',\n",
      "       'CNN_all', 'CNN_0-19', 'rate_total', 'rate_019'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55701ec-5dd6-44d0-9abd-e4c171c1a461",
   "metadata": {},
   "source": [
    "**Apply data reduction technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da2cd1f3-bdd8-4449-8312-7d21dc2dc5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6156, 10)\n"
     ]
    }
   ],
   "source": [
    "if DATA_REDUCER_SETTINGS['TYPE'] == 'PLS':\n",
    "    climatic_vars_reduced = pls_reducer(\n",
    "        X_climatic, y_dengue, \n",
    "        DATA_REDUCER_SETTINGS['NUMBER OF COMPONENTS']['CLIMATIC VARIABLES']\n",
    "    )\n",
    "    geo_vars_reduced = pls_reducer(\n",
    "        X_geo, y_dengue, \n",
    "        DATA_REDUCER_SETTINGS['NUMBER OF COMPONENTS']['GEO VARIABLES']\n",
    "    )\n",
    "    socio_vars_reduced = pls_reducer(\n",
    "        X_socio, y_dengue, \n",
    "        DATA_REDUCER_SETTINGS['NUMBER OF COMPONENTS']['SOCIO VARIABLES']\n",
    "    )\n",
    "    print(socio_vars_reduced.shape)\n",
    "elif DATA_REDUCER_SETTINGS['TYPE'] == 'PCA':\n",
    "    climatic_vars_reduced = pca_reducer(\n",
    "        X_climatic, \n",
    "        DATA_REDUCER_SETTINGS['NUMBER OF COMPONENTS']['CLIMATIC VARIABLES']\n",
    "    )\n",
    "    geo_vars_reduced = pca_reducer(\n",
    "        X_geo, \n",
    "        DATA_REDUCER_SETTINGS['NUMBER OF COMPONENTS']['GEO VARIABLES']\n",
    "    )\n",
    "    socio_vars_reduced = pca_reducer(\n",
    "        X_socio, \n",
    "        DATA_REDUCER_SETTINGS['NUMBER OF COMPONENTS']['SOCIO VARIABLES']\n",
    "    )\n",
    "else:\n",
    "    print('No data reduction.')\n",
    "    climatic_vars_reduced, geo_vars_reduced, socio_vars_reduced = X_climatic, X_geo, X_socio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f809093-61b1-4a90-8057-ba7c158181a0",
   "metadata": {},
   "source": [
    "## Order reduced data in a new dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a4e11-801a-43ad-a0e8-179a06aa6fdf",
   "metadata": {},
   "source": [
    "**Normalize remaining variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e02fb186-5561-4ea7-9e3a-9b9ea7e13a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Year', 'Month', 'CD_UF', 'area_km2', 'NDVI_d',\n",
      "       'dewpoint_temperature_2m_d', 'humidity_d', 'max_temperature_2m_d',\n",
      "       'min_temperature_2m_d', 'surface_pressure_d', 'temperature_2m_d',\n",
      "       'total_precipitation_d', 'u_component_of_wind_10m_d',\n",
      "       'v_component_of_wind_10m_d', 'max_elevation_d', 'mean_elevation_d',\n",
      "       'min_elevation_d', 'stdDev_elevation_d', 'variance_elevation_d',\n",
      "       'PopTotal_Urban_UF', 'PopTotal_Rural_UF', 'cases0_19', 'cases20_99',\n",
      "       'Forest_Cover_Percent', 'Urban_Cover_Percent', 'ivs',\n",
      "       'ivs_infraestrutura_urbana', 'ivs_capital_humano',\n",
      "       'ivs_renda_e_trabalho', 't_sem_agua_esgoto', 't_sem_lixo',\n",
      "       't_vulner_mais1h', 't_analf_15m', 't_cdom_fundin', 't_p15a24_nada',\n",
      "       't_vulner', 't_desocup18m', 't_p18m_fundin_informal', 'idhm',\n",
      "       'idhm_long', 'idhm_educ', 'idhm_renda', 'idhm_educ_sub_esc',\n",
      "       't_pop18m_fundc', 'idhm_educ_sub_freq', 'renda_per_capita', 'pea10a14',\n",
      "       'pea15a17', 'pea18m', 't_eletrica', 't_densidadem2', 'rdpc_def_vulner',\n",
      "       't_analf_18m', 't_formal_18m', 't_fundc_ocup18m', 't_medioc_ocup18m',\n",
      "       'CNN_all', 'CNN_0-19', 'rate_total', 'rate_019'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb037b45-3d95-495a-9c5c-2e744c18e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing remaining variables\n",
    "x_excluded = scaler.fit_transform(dataframe[GROUPED_VARS['EXCLUDED']].values)\n",
    "X_auxiliar = scaler.fit_transform(dataframe[GROUPED_VARS['AUXILIAR']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eabf96-de24-4952-977d-ceb2fc6424a0",
   "metadata": {},
   "source": [
    "**Create a new database with the reduced, the auxiliar and Dengue variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e25d82b0-5bb3-4ff4-b5f0-f5f75ccb7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_effects = np.array([\n",
    "    dataframe.CD_UF.values * dataframe.Month.values,\n",
    "    dataframe.CD_UF.values * dataframe.Year.values,\n",
    "    dataframe.CD_UF.values * dataframe.Month.values * dataframe.Year.values\n",
    "]).T\n",
    "rand_effects_scaled = scaler.fit_transform(rand_effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3dff9895-34a6-43dd-a6d6-532ec65279b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new database with the reduced, the auxiliary, and Dengue variables\n",
    "independent = {'Year': dataframe.Year.values, 'dep_id': dataframe.CD_UF.values}\n",
    "for i, var in enumerate(GROUPED_VARS['EXCLUDED']):\n",
    "    independent[var] = x_excluded[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2283e554-f24b-4ae9-a027-f61b63a3f47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced DataFrame shape: (5184, 42)\n"
     ]
    }
   ],
   "source": [
    "auxiliar = {\n",
    "    'Month': X_auxiliar[:, 0],\n",
    "    'cases20_99': X_auxiliar[:, 1], \n",
    "    'cases0_19': X_auxiliar[:, 2],\n",
    "    'RandEffects1': rand_effects_scaled[:, 0],\n",
    "    'RandEffects2': rand_effects_scaled[:, 1],\n",
    "    'RandEffects3': rand_effects_scaled[:, 2]\n",
    "}\n",
    "\n",
    "climatic = {f'PCA{i}-Climatic': climatic_vars_reduced[:, i] for i in range(climatic_vars_reduced.shape[1])}\n",
    "geo = {f'PCA{i}-Geo': geo_vars_reduced[:, i] for i in range(geo_vars_reduced.shape[1])}\n",
    "socio = {f'PCA{i}-Socio': socio_vars_reduced[:, i] for i in range(socio_vars_reduced.shape[1])}\n",
    "\n",
    "dengue = {'rate_total': y_dengue[:,0], 'rate_019': y_dengue[:,1]}\n",
    "\n",
    "columns = {**independent, **auxiliar, **climatic, **geo, **socio, **dengue}\n",
    "\n",
    "reduced_dataframe = pd.DataFrame(columns)\n",
    "reduced_dataframe = reduced_dataframe[reduced_dataframe['Year'] >= 2004]\n",
    "\n",
    "# Save the data\n",
    "reduced_dataframe.to_csv('reduced_2004_2019.csv', index=False)\n",
    "print(\"Reduced DataFrame shape:\", reduced_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5116f9b9-708d-4524-9429-b19eec08d0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'dep_id', 't_fundc_ocup18m', 't_medioc_ocup18m',\n",
      "       'PopTotal_Urban_UF', 'PopTotal_Rural_UF', 'total_precipitation_d',\n",
      "       'surface_pressure_d', 'area_km2', 'humidity_d', 'temperature_2m_d',\n",
      "       'min_temperature_2m_d', 'CNN_all', 'CNN_0-19', 'Month', 'cases20_99',\n",
      "       'cases0_19', 'RandEffects1', 'RandEffects2', 'RandEffects3',\n",
      "       'PCA0-Climatic', 'PCA1-Climatic', 'PCA2-Climatic', 'PCA3-Climatic',\n",
      "       'PCA0-Geo', 'PCA1-Geo', 'PCA2-Geo', 'PCA3-Geo', 'PCA4-Geo', 'PCA5-Geo',\n",
      "       'PCA0-Socio', 'PCA1-Socio', 'PCA2-Socio', 'PCA3-Socio', 'PCA4-Socio',\n",
      "       'PCA5-Socio', 'PCA6-Socio', 'PCA7-Socio', 'PCA8-Socio', 'PCA9-Socio',\n",
      "       'rate_total', 'rate_019'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(reduced_dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31424ab9-a2b8-42c7-adfc-bccfa632700a",
   "metadata": {},
   "source": [
    "## Create training and validation data\n",
    "**First of all, the dataframe is divided in two sub-dataframes (training and validation) by using the variable *Year***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12df84b8-465d-4183-a8b1-0985af1f5bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (5184, 41)\n",
      "Columns: Index(['Year', 'dep_id', 't_fundc_ocup18m', 't_medioc_ocup18m',\n",
      "       'PopTotal_Urban_UF', 'PopTotal_Rural_UF', 'total_precipitation_d',\n",
      "       'surface_pressure_d', 'area_km2', 'humidity_d', 'temperature_2m_d',\n",
      "       'min_temperature_2m_d', 'CNN_all', 'CNN_0-19', 'Month', 'cases20_99',\n",
      "       'cases0_19', 'RandEffects1', 'RandEffects2', 'RandEffects3',\n",
      "       'PCA0-Climatic', 'PCA1-Climatic', 'PCA2-Climatic', 'PCA3-Climatic',\n",
      "       'PCA0-Geo', 'PCA1-Geo', 'PCA2-Geo', 'PCA3-Geo', 'PCA4-Geo', 'PCA5-Geo',\n",
      "       'PCA0-Socio', 'PCA1-Socio', 'PCA2-Socio', 'PCA3-Socio', 'PCA4-Socio',\n",
      "       'PCA5-Socio', 'mosquito_interest', 'sintomas_dengue_interest',\n",
      "       'dengue_interest', 'DengRate_all', 'DengRate_019'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(\"..\", \"google trends\", \"merged_dataset.csv\")\n",
    "reduced_dataframe = pd.read_csv(dataset_path)\n",
    "# Print shape and column names\n",
    "print(\"Dataset Shape:\", reduced_dataframe.shape)\n",
    "print(\"Columns:\", reduced_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "511c13d0-43eb-4864-bc6a-deccbbdeeabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 4212, Validation Size: 972\n",
      "Missing values in training set: 0\n",
      "Missing values in validation set: 0\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "training_dataframe = reduced_dataframe[reduced_dataframe.Year < 2017].copy()\n",
    "validation_dataframe = reduced_dataframe[reduced_dataframe.Year >= 2017].copy()\n",
    "print(f\"Training Size: {len(training_dataframe)}, Validation Size: {len(validation_dataframe)}\")\n",
    "# Check for missing values\n",
    "print(\"Missing values in training set:\", training_dataframe.isnull().sum().sum())\n",
    "print(\"Missing values in validation set:\", validation_dataframe.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58558a1e-8bfb-4c05-9187-ac5a5a4d3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (if any)\n",
    "if training_dataframe.isnull().sum().sum() > 0 or validation_dataframe.isnull().sum().sum() > 0:\n",
    "    # Here you would implement some strategy for dealing with missing data\n",
    "    # e.g., `training_dataframe = training_dataframe.fillna(method='ffill')`\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a62353b-1a0c-47b9-b14a-430e9f08b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataframe[\"DengRate_all_log\"] = np.log1p(training_dataframe[\"DengRate_all\"])\n",
    "validation_dataframe[\"DengRate_all_log\"] = np.log1p(validation_dataframe[\"DengRate_all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81f3f17e-0177-45b9-953e-6561f9389cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace 'rate_total' with 'DengRate_all' (or 'DengRate_019' if needed)\n",
    "plt.hist(training_dataframe[\"DengRate_all\"], bins=30, alpha=0.5, label=\"Train\")\n",
    "plt.hist(validation_dataframe[\"DengRate_all\"], bins=30, alpha=0.5, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ffe7db-16e6-4515-938d-a786b2c3c4f3",
   "metadata": {},
   "source": [
    "**Then the dataset handler is initialized. This object will handle all the operations needed to create, reshape and augment the training and validation dataset to fit the requirements of each Deep Learning or Machine Learning model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79b26a8b-060a-43db-8eec-85f4dcc02b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetHandler import datasetHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a029c839-1014-4634-92a0-ed9da9cf39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset handler with filtered data\n",
    "dataset_handler = datasetHandler(training_dataframe, validation_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50f1d466-e5d1-44ea-a2f2-3e9b3a18de9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Preparing data with window size 12 and prediction horizon 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training shape (3888, 12, 42)\n",
      "Y Training shape (3888, 2)\n",
      "Processing departments 26 of 27\t\t\n",
      "X Validation shape (648, 12, 42)\n",
      "Y Validation shape (648, 2)\n",
      "Processing departments 26 of 27\t\t"
     ]
    }
   ],
   "source": [
    "# Fetch training/validation data & indices\n",
    "x_train, y_train, x_val, y_val, train_indices, val_indices = dataset_handler.get_data(\n",
    "    DATA_PROCESSING_SETTINGS[\"T LEARNING\"], DATA_PROCESSING_SETTINGS[\"T PREDICTION\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dde28a7a-979c-42ce-92ac-d96e7766dce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X Training shape: (3888, 12, 42)\n",
      "Y Training shape: (3888, 2)\n",
      "X Validation shape: (648, 12, 42)\n",
      "Y Validation shape: (648, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes\n",
    "print(\"\\nX Training shape:\", x_train.shape)\n",
    "print(\"Y Training shape:\", y_train.shape)\n",
    "print(\"X Validation shape:\", x_val.shape)\n",
    "print(\"Y Validation shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d7d905-0d6b-4f4f-a862-db0900218f1a",
   "metadata": {},
   "source": [
    "**Apply data augmention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04749424-49f8-409e-93e1-e51258c584e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying data augmentation with dynamic noise scaling\n",
    "x_train_a, y_train_a, x_val_a, y_val_a = dataset_handler.augment(\n",
    "    x_train, y_train, x_val, y_val, DATA_PROCESSING_SETTINGS[\"AUGMENTATION\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74f43148-63cf-47db-9870-5387af62b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training Augmented shape: (11664, 12, 42)\n",
      "Y Training Augmented shape: (11664, 2)\n",
      "X Validation Augmented shape: (1944, 12, 42)\n",
      "Y Validation Augmented shape: (1944, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print augmented shapes\n",
    "print(\"X Training Augmented shape:\", x_train_a.shape)\n",
    "print(\"Y Training Augmented shape:\", y_train_a.shape)\n",
    "print(\"X Validation Augmented shape:\", x_val_a.shape)\n",
    "print(\"Y Validation Augmented shape:\", y_val_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "625eba45-7daf-41c2-87d0-d5c79ab1fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example before training or prediction\n",
    "# training_dataframe = remove_outliers(training_dataframe, 'DengRate_all')\n",
    "# validation_dataframe = remove_outliers(validation_dataframe, 'DengRate_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e25b4f-43ac-43bb-ad8d-e9d7565c1812",
   "metadata": {},
   "source": [
    "# TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42061de7-ff17-4873-8e29-4f778ef5ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanp\\.conda\\envs\\minor\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, BatchNormalization, Dropout, Input, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc, average_precision_score\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from config import TCN_SETTINGS, DEP_NAMES\n",
    "from datasetHandler import datasetHandler\n",
    "import shap\n",
    "from tensorflow.keras import layers, models, regularizers, Input\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b5e8782-4bd5-4db2-affd-bae3d66c21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for metrics calculation\n",
    "def calculate_nrmse(true_values, predicted_values):\n",
    "    return mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "def calculate_mae(true_values, predicted_values):\n",
    "    return mean_absolute_error(true_values, predicted_values)\n",
    "\n",
    "def calculate_mse(true_values, predicted_values):\n",
    "    return mean_squared_error(true_values, predicted_values)\n",
    "\n",
    "def calculate_rmse(mse):\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def calculate_mape(true_values, predicted_values):\n",
    "    return mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "def calculate_r2(true_values, predicted_values):\n",
    "    return r2_score(true_values, predicted_values)\n",
    "\n",
    "def discretize_to_binary(values, threshold=0.5):\n",
    "    return np.where(values > threshold, 1, 0)\n",
    "\n",
    "def plot_confusion_matrix(true_values, predicted_values, department_name, metric_type=\"All\"):\n",
    "    cm = confusion_matrix(true_values, predicted_values)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "    ax.set_title(f'Confusion Matrix: {department_name} - {metric_type}')\n",
    "    plt.show()\n",
    "\n",
    "# Define model architecture\n",
    "def build_tcn_model_v2(input_shape, output_units, num_filters, dropout_rate, l2_reg, num_residual_blocks):\n",
    "    def residual_block(x, filters, dilation_rate):\n",
    "        shortcut = x\n",
    "        x = layers.Conv1D(filters, 3, padding='causal', activation='relu',\n",
    "                         dilation_rate=dilation_rate, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.add([x, shortcut])\n",
    "        return layers.ReLU()(x)\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(num_filters, 3, padding='causal', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(TCN_SETTINGS['INITIAL_DROPOUT_RATE'])(x)\n",
    "    \n",
    "    for dilation in TCN_SETTINGS['DILATION_RATES'][:num_residual_blocks]:\n",
    "        x = residual_block(x, num_filters, dilation)\n",
    "        \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(output_units, activation='linear')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "class ImprovedTCNNet:\n",
    "    def __init__(self, shape, output_units=2):\n",
    "        self.shape = shape\n",
    "        self.epochs = TCN_SETTINGS['EPOCHS']\n",
    "        self.batch_size = TCN_SETTINGS['BATCH_SIZE']\n",
    "        self.lr = TCN_SETTINGS['LEARNING_RATE']\n",
    "        self.early_stopping_rounds = TCN_SETTINGS['EARLY_STOPPING_PATIENCE']\n",
    "        self.dropout_rate = TCN_SETTINGS['DROPOUT_RATE']\n",
    "        self.l2_regularization = 1e-3  # Default, adjust if needed\n",
    "        self.num_filters = TCN_SETTINGS['NUM_FILTERS']\n",
    "        self.num_residual_blocks = len(TCN_SETTINGS['DILATION_RATES'])\n",
    "        \n",
    "        # Build the uncompiled model\n",
    "        self.model = build_tcn_model_v2(\n",
    "            self.shape, output_units, self.num_filters,\n",
    "            self.dropout_rate, self.l2_regularization, self.num_residual_blocks\n",
    "        )\n",
    "        \n",
    "        # Compile the model\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(learning_rate=self.lr),\n",
    "            loss=TCN_SETTINGS['LOSS'],\n",
    "            metrics=TCN_SETTINGS['EVALUATION_METRIC']\n",
    "        )\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"Model loaded successfully from {model_path}\")\n",
    "\n",
    "    def train(self, training, validation, output_path):\n",
    "        es = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=self.early_stopping_rounds,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            x=training[0],\n",
    "            y=training[1],\n",
    "            validation_data=(validation[0], validation[1]),\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            callbacks=[es, lr_scheduler],\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Improved TCN Model Loss Curve')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "        today = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "        model_filename = f\"TCN-new-search-{today}.keras\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        save_path = os.path.join(output_path, model_filename)\n",
    "        self.model.save(save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6834c8b-7027-4065-bf4e-22b49c4407d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Utility functions for metrics calculation\n",
    "# def calculate_nrmse(true_values, predicted_values):\n",
    "#     rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "#     return rmse / (true_values.max() - true_values.min()) if true_values.max() != true_values.min() else 0\n",
    "\n",
    "# def calculate_mae(true_values, predicted_values):\n",
    "#     return mean_absolute_error(true_values, predicted_values)\n",
    "\n",
    "# def calculate_mse(true_values, predicted_values):\n",
    "#     return mean_squared_error(true_values, predicted_values)\n",
    "\n",
    "# def calculate_rmse(mse):\n",
    "#     return np.sqrt(mse)\n",
    "\n",
    "# def calculate_mape(true_values, predicted_values):\n",
    "#     mask = true_values > 0\n",
    "#     return np.mean(np.abs((true_values[mask] - predicted_values[mask]) / true_values[mask])) * 100 if mask.any() else 0\n",
    "\n",
    "# def calculate_r2(true_values, predicted_values):\n",
    "#     return r2_score(true_values, predicted_values)\n",
    "\n",
    "# # TCN Model Definition\n",
    "# def build_tcn_model_v2(input_shape, output_units, num_filters, dropout_rate, l2_reg, num_residual_blocks):\n",
    "#     def residual_block(x, filters, dilation_rate):\n",
    "#         shortcut = x\n",
    "#         x = layers.Conv1D(filters, 3, padding='causal', activation='relu',\n",
    "#                           dilation_rate=dilation_rate, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.Dropout(dropout_rate)(x)\n",
    "#         x = layers.add([x, shortcut])\n",
    "#         return layers.ReLU()(x)\n",
    "\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     x = layers.Conv1D(num_filters, 3, padding='causal', activation='relu')(inputs)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Dropout(TCN_SETTINGS['INITIAL_DROPOUT_RATE'])(x)\n",
    "    \n",
    "#     for dilation in TCN_SETTINGS['DILATION_RATES'][:num_residual_blocks]:\n",
    "#         x = residual_block(x, num_filters, dilation)\n",
    "        \n",
    "#     x = layers.GlobalAveragePooling1D()(x)\n",
    "#     outputs = layers.Dense(output_units, activation='linear')(x)\n",
    "#     return models.Model(inputs, outputs)\n",
    "\n",
    "# class ImprovedTCNNet:\n",
    "#     def __init__(self, shape, output_units=2):\n",
    "#         self.shape = shape\n",
    "#         self.epochs = TCN_SETTINGS['EPOCHS']\n",
    "#         self.batch_size = TCN_SETTINGS['BATCH_SIZE']\n",
    "#         self.lr = TCN_SETTINGS['LEARNING_RATE']\n",
    "#         self.early_stopping_rounds = TCN_SETTINGS['EARLY_STOPPING_PATIENCE']\n",
    "#         self.dropout_rate = TCN_SETTINGS['DROPOUT_RATE']\n",
    "#         self.l2_regularization = TCN_SETTINGS['L2_REGULARIZATION']\n",
    "#         self.num_filters = TCN_SETTINGS['NUM_FILTERS']\n",
    "#         self.num_residual_blocks = len(TCN_SETTINGS['DILATION_RATES'])\n",
    "        \n",
    "#         self.model = build_tcn_model_v2(\n",
    "#             self.shape, output_units, self.num_filters,\n",
    "#             self.dropout_rate, self.l2_regularization, self.num_residual_blocks\n",
    "#         )\n",
    "        \n",
    "#         self.model.compile(\n",
    "#             optimizer=Adam(learning_rate=self.lr),\n",
    "#             loss=TCN_SETTINGS['LOSS'],\n",
    "#             metrics=TCN_SETTINGS['EVALUATION_METRIC']\n",
    "#         )\n",
    "    \n",
    "#     def load(self, model_path):\n",
    "#         self.model = tf.keras.models.load_model(model_path)\n",
    "#         print(f\"Model loaded successfully from {model_path}\")\n",
    "\n",
    "#     def train(self, training, validation, output_path):\n",
    "#         es = EarlyStopping(\n",
    "#             monitor='val_loss',\n",
    "#             min_delta=0.001,\n",
    "#             patience=self.early_stopping_rounds,\n",
    "#             verbose=1,\n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "        \n",
    "#         lr_scheduler = ReduceLROnPlateau(\n",
    "#             monitor='val_loss',\n",
    "#             factor=0.5,\n",
    "#             patience=5,\n",
    "#             min_lr=1e-6,\n",
    "#             verbose=1\n",
    "#         )\n",
    "        \n",
    "#         print(f\"Training Data Shapes: Input {training[0].shape}, Output {training[1].shape}\")\n",
    "#         print(f\"Validation Data Shapes: Input {validation[0].shape}, Output {validation[1].shape}\")\n",
    "\n",
    "#         history = self.model.fit(\n",
    "#             x=training[0],\n",
    "#             y=training[1],\n",
    "#             validation_data=(validation[0], validation[1]),\n",
    "#             epochs=self.epochs,\n",
    "#             batch_size=self.batch_size,\n",
    "#             callbacks=[es, lr_scheduler],\n",
    "#             shuffle=True,\n",
    "#             verbose=1\n",
    "#         )\n",
    "\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         plt.plot(history.history['loss'], label='Train Loss')\n",
    "#         plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "#         plt.legend()\n",
    "#         plt.title('Improved TCN Model Loss Curve')\n",
    "#         plt.xlabel('Epochs')\n",
    "#         plt.ylabel('Loss')\n",
    "#         plt.show()\n",
    "\n",
    "#         today = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "#         model_filename = f\"TCN-new-search-{today}.keras\"\n",
    "#         save_path = os.path.join(output_path, model_filename)\n",
    "#         os.makedirs(output_path, exist_ok=True)\n",
    "#         self.model.save(save_path)\n",
    "#         print(f\"Model saved to {save_path}\")\n",
    "#         return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "beb7d6b0-1ea6-4813-a3ac-4287bd8b28d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for saved models...\n",
      "Model loaded successfully from C:\\Users\\amanp\\Desktop\\MINOR\\projj\\code\\saved_models\\Brazil\\TCN-new-search-19-02-2025-15-40-40.keras\n",
      "Loading model from: C:\\Users\\amanp\\Desktop\\MINOR\\projj\\code\\saved_models\\Brazil\\TCN-new-search-19-02-2025-15-40-40.keras\n",
      "Making predictions...\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Rondônia: Validation entries 36, Training entries 156\n",
      "Acre: Validation entries 36, Training entries 156\n",
      "Amazonas: Validation entries 36, Training entries 156\n",
      "Roraima: Validation entries 36, Training entries 156\n",
      "Pará: Validation entries 36, Training entries 156\n",
      "Amapá: Validation entries 36, Training entries 156\n",
      "Tocantins: Validation entries 36, Training entries 156\n",
      "Maranhão: Validation entries 36, Training entries 156\n",
      "Piauí: Validation entries 36, Training entries 156\n",
      "Ceará: Validation entries 36, Training entries 156\n",
      "Rio Grande do Norte: Validation entries 36, Training entries 156\n",
      "Paraíba: Validation entries 36, Training entries 156\n",
      "Pernambuco: Validation entries 36, Training entries 156\n",
      "Alagoas: Validation entries 36, Training entries 156\n",
      "Sergipe: Validation entries 36, Training entries 156\n",
      "Bahia: Validation entries 36, Training entries 156\n",
      "Minas Gerais: Validation entries 36, Training entries 156\n",
      "Espírito Santo: Validation entries 36, Training entries 156\n",
      "Rio de Janeiro: Validation entries 36, Training entries 156\n",
      "São Paulo: Validation entries 36, Training entries 156\n",
      "Paraná: Validation entries 36, Training entries 156\n",
      "Santa Catarina: Validation entries 36, Training entries 156\n",
      "Rio Grande do Sul: Validation entries 36, Training entries 156\n",
      "Mato Grosso do Sul: Validation entries 36, Training entries 156\n",
      "Mato Grosso: Validation entries 36, Training entries 156\n",
      "Goiás: Validation entries 36, Training entries 156\n",
      "Distrito Federal: Validation entries 36, Training entries 156\n",
      "Results saved to C:\\Users\\amanp\\Desktop\\MINOR\\projj\\code\\metrics\\Brazil\\TCN_new_model_search_20-02-2025-21-21-14.csv\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation Setup\n",
    "output_path = os.path.join(config['output'], \"Brazil\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "TRAINING = False\n",
    "\n",
    "# Define metric columns\n",
    "metric_columns = [\n",
    "    'Department',\n",
    "    'MAE (DengRate_all) Val', 'RMSE (DengRate_all) Val', 'MAPE (DengRate_all) Val', 'R2 (DengRate_all) Val', 'MSE (DengRate_all) Val',\n",
    "    'MAE (DengRate_019) Val', 'RMSE (DengRate_019) Val', 'MAPE (DengRate_019) Val', 'R2 (DengRate_019) Val', 'MSE (DengRate_019) Val',\n",
    "    'MAE (DengRate_all) Train', 'RMSE (DengRate_all) Train', 'MAPE (DengRate_all) Train', 'R2 (DengRate_all) Train', 'MSE (DengRate_all) Train',\n",
    "    'MAE (DengRate_019) Train', 'RMSE (DengRate_019) Train', 'MAPE (DengRate_019) Train', 'R2 (DengRate_019) Train', 'MSE (DengRate_019) Train'\n",
    "]\n",
    "\n",
    "# Initialize TCN model\n",
    "tcn = ImprovedTCNNet(trainingT[0].shape[1:])  # Use shape from training data\n",
    "\n",
    "if TRAINING:\n",
    "    print(\"Training the model...\")\n",
    "    trainingT, validationT = dataset_handler.prepare_data_TCN(x_train_a, y_train_a, x_val_a, y_val_a)\n",
    "    history = tcn.train(trainingT, validationT, output_path=output_path)\n",
    "else:\n",
    "    print(\"Checking for saved models...\")\n",
    "    tcn_models = glob(os.path.join(output_path, \"TCN-new-search-*.keras\"))\n",
    "    if not tcn_models:\n",
    "        print('No file with such pattern was found in the directory. Run TRAINING = True first.')\n",
    "        exit()\n",
    "    else:\n",
    "        tcn_models.sort(key=os.path.getmtime, reverse=True)\n",
    "        tcn.load(tcn_models[0])\n",
    "        print(f\"Loading model from: {tcn_models[0]}\")\n",
    "\n",
    "        # Scaler for target only (matching old LSTM preprocessing)\n",
    "        scaler = MinMaxScaler()\n",
    "        y_dengue = scaler.fit_transform(dataframe[GROUPED_VARS['DENGUE']].values)\n",
    "\n",
    "        # Re-prepare data for inference\n",
    "        trainingT, validationT = dataset_handler.prepare_data_TCN(x_train_a, y_train_a, x_val_a, y_val_a)\n",
    "\n",
    "        # Predictions\n",
    "        print(\"Making predictions...\")\n",
    "        preds_tra = tcn.model.predict(trainingT[0])\n",
    "        preds_tra[preds_tra < 0] = 0\n",
    "        preds_val = tcn.model.predict(validationT[0])\n",
    "        preds_val[preds_val < 0] = 0\n",
    "\n",
    "        # Inverse transform predictions and ground truth\n",
    "        preds_val_original = scaler.inverse_transform(preds_val)\n",
    "        y_val_original = scaler.inverse_transform(validationT[1])\n",
    "        preds_tra_original = scaler.inverse_transform(preds_tra)\n",
    "        y_train_original = scaler.inverse_transform(trainingT[1])\n",
    "\n",
    "        # Index mappings (adopting old LSTM logic)\n",
    "        y_val_indices_df = pd.DataFrame(val_indices, columns=['actual_index'])\n",
    "        y_train_indices_df = pd.DataFrame(train_indices, columns=['actual_index'])\n",
    "\n",
    "        # Collect results by department\n",
    "        results = []\n",
    "\n",
    "        for department_idx, department_name in DEP_NAMES.items():\n",
    "            department_rows_val = validation_dataframe[validation_dataframe['dep_id'] == department_idx]\n",
    "            department_rows_train = training_dataframe[training_dataframe['dep_id'] == department_idx]\n",
    "\n",
    "            count_val = department_rows_val.shape[0]\n",
    "            count_train = department_rows_train.shape[0]\n",
    "            print(f\"{department_name}: Validation entries {count_val}, Training entries {count_train}\")\n",
    "\n",
    "            if department_rows_val.empty or department_rows_train.empty:\n",
    "                print(f\"Skipping {department_name} due to empty data.\")\n",
    "                results.append({'Department': department_name, **{k: np.nan for k in metric_columns[1:]}})\n",
    "                continue\n",
    "\n",
    "            department_indices_val = department_rows_val.index.tolist()\n",
    "            department_indices_train = department_rows_train.index.tolist()\n",
    "\n",
    "            # Use .isin() for index matching (old LSTM approach)\n",
    "            matching_indices_val = y_val_indices_df[y_val_indices_df['actual_index'].isin(department_indices_val)].index\n",
    "            matching_indices_train = y_train_indices_df[y_train_indices_df['actual_index'].isin(department_indices_train)].index\n",
    "\n",
    "            if matching_indices_val.empty or matching_indices_train.empty:\n",
    "                print(f\"No matching indices for {department_name}\")\n",
    "                results.append({'Department': department_name, **{k: np.nan for k in metric_columns[1:]}})\n",
    "                continue\n",
    "\n",
    "            # Validation Metrics\n",
    "            metrics = {}\n",
    "            if len(matching_indices_val) > 1:\n",
    "                true_dengrate_all_val = y_val_original[matching_indices_val, 0]\n",
    "                true_dengrate_019_val = y_val_original[matching_indices_val, 1]\n",
    "                predicted_dengrate_all_val = preds_val_original[matching_indices_val, 0]\n",
    "                predicted_dengrate_019_val = preds_val_original[matching_indices_val, 1]\n",
    "\n",
    "                metrics.update({\n",
    "                    'MAE (DengRate_all) Val': calculate_mae(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'RMSE (DengRate_all) Val': calculate_rmse(calculate_mse(true_dengrate_all_val, predicted_dengrate_all_val)),\n",
    "                    'MAPE (DengRate_all) Val': calculate_mape(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'R2 (DengRate_all) Val': calculate_r2(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'MSE (DengRate_all) Val': calculate_mse(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'MAE (DengRate_019) Val': calculate_mae(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                    'RMSE (DengRate_019) Val': calculate_rmse(calculate_mse(true_dengrate_019_val, predicted_dengrate_019_val)),\n",
    "                    'MAPE (DengRate_019) Val': calculate_mape(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                    'R2 (DengRate_019) Val': calculate_r2(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                    'MSE (DengRate_019) Val': calculate_mse(true_dengrate_019_val, predicted_dengrate_019_val)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Not enough validation data for {department_name} to calculate metrics.\")\n",
    "                metrics.update({k: np.nan for k in metric_columns[1:] if 'Val' in k})\n",
    "\n",
    "            # Training Metrics\n",
    "            if len(matching_indices_train) > 1:\n",
    "                true_dengrate_all_train = y_train_original[matching_indices_train, 0]\n",
    "                true_dengrate_019_train = y_train_original[matching_indices_train, 1]\n",
    "                predicted_dengrate_all_train = preds_tra_original[matching_indices_train, 0]\n",
    "                predicted_dengrate_019_train = preds_tra_original[matching_indices_train, 1]\n",
    "\n",
    "                metrics.update({\n",
    "                    'MAE (DengRate_all) Train': calculate_mae(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'RMSE (DengRate_all) Train': calculate_rmse(calculate_mse(true_dengrate_all_train, predicted_dengrate_all_train)),\n",
    "                    'MAPE (DengRate_all) Train': calculate_mape(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'R2 (DengRate_all) Train': calculate_r2(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'MSE (DengRate_all) Train': calculate_mse(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'MAE (DengRate_019) Train': calculate_mae(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                    'RMSE (DengRate_019) Train': calculate_rmse(calculate_mse(true_dengrate_019_train, predicted_dengrate_019_train)),\n",
    "                    'MAPE (DengRate_019) Train': calculate_mape(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                    'R2 (DengRate_019) Train': calculate_r2(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                    'MSE (DengRate_019) Train': calculate_mse(true_dengrate_019_train, predicted_dengrate_019_train)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Not enough training data for {department_name} to calculate metrics.\")\n",
    "                metrics.update({k: np.nan for k in metric_columns[1:] if 'Train' in k})\n",
    "\n",
    "            # Append results\n",
    "            results.append({'Department': department_name, **metrics})\n",
    "\n",
    "        # Save results to CSV\n",
    "        results_df = pd.DataFrame(results, columns=metric_columns)\n",
    "        today = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "        out_csv = os.path.join(config['metrics'], \"Brazil\", f'TCN_new_model_search_{today}.csv')\n",
    "        os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "        results_df.to_csv(out_csv, index=False)\n",
    "        print(f\"Results saved to {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0cf7a99b-a948-4deb-8def-97cbc435caab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'dep_id', 't_fundc_ocup18m', 't_medioc_ocup18m',\n",
      "       'PopTotal_Urban_UF', 'PopTotal_Rural_UF', 'total_precipitation_d',\n",
      "       'surface_pressure_d', 'area_km2', 'humidity_d', 'temperature_2m_d',\n",
      "       'min_temperature_2m_d', 'CNN_all', 'CNN_0-19', 'Month', 'cases20_99',\n",
      "       'cases0_19', 'RandEffects1', 'RandEffects2', 'RandEffects3',\n",
      "       'PCA0-Climatic', 'PCA1-Climatic', 'PCA2-Climatic', 'PCA3-Climatic',\n",
      "       'PCA0-Geo', 'PCA1-Geo', 'PCA2-Geo', 'PCA3-Geo', 'PCA4-Geo', 'PCA5-Geo',\n",
      "       'PCA0-Socio', 'PCA1-Socio', 'PCA2-Socio', 'PCA3-Socio', 'PCA4-Socio',\n",
      "       'PCA5-Socio', 'mosquito_interest', 'sintomas_dengue_interest',\n",
      "       'dengue_interest', 'DengRate_all', 'DengRate_019', 'DengRate_all_log'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(validation_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "749bcd3f-6acc-45e6-985f-be72f5f9b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_val_original shape: (1944, 2)\n",
      "preds_val_original shape: (1944, 2)\n",
      "matching_indices_val: [5160 5161 5162 5163 5164 5165 5166 5167 5168 5169 5170 5171 5172 5173\n",
      " 5174 5175 5176 5177 5178 5179 5180 5181 5182 5183]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_val_original shape:\", y_val_original.shape)\n",
    "print(\"preds_val_original shape:\", preds_val_original.shape)\n",
    "print(\"matching_indices_val:\", matching_indices_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c5581bc-f6a8-4980-847e-1fab7fb9bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE DengRate_all: 1595.4297240954065, RMSE DengRate_all: 39.942830697077625, MAE DengRate_all: 20.719682705667918, MAPE DengRate_all: 174744500324800.66, R2 DengRate_all: 0.8170969254114541\n",
      "MSE DengRate_019: 497.7928224511642, RMSE DengRate_019: 22.311271197562103, MAE DengRate_019: 14.360156068061732, MAPE DengRate_019: 101083451617605.88, R2 DengRate_019: 0.8304722131737516\n"
     ]
    }
   ],
   "source": [
    "mse_dengrate_all = mean_squared_error(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "rmse_dengrate_all = np.sqrt(mse_dengrate_all)\n",
    "mae_dengrate_all = mean_absolute_error(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "mape_dengrate_all = mean_absolute_percentage_error(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "r2_dengrate_all = r2_score(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "\n",
    "# For the second output (DengRate_019):\n",
    "mse_dengrate_019 = mean_squared_error(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "rmse_dengrate_019 = np.sqrt(mse_dengrate_019)\n",
    "mae_dengrate_019 = mean_absolute_error(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "mape_dengrate_019 = mean_absolute_percentage_error(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "r2_dengrate_019 = r2_score(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "\n",
    "# Print the results\n",
    "print(f\"MSE DengRate_all: {mse_dengrate_all}, RMSE DengRate_all: {rmse_dengrate_all}, MAE DengRate_all: {mae_dengrate_all}, MAPE DengRate_all: {mape_dengrate_all}, R2 DengRate_all: {r2_dengrate_all}\")\n",
    "print(f\"MSE DengRate_019: {mse_dengrate_019}, RMSE DengRate_019: {rmse_dengrate_019}, MAE DengRate_019: {mae_dengrate_019}, MAPE DengRate_019: {mape_dengrate_019}, R2 DengRate_019: {r2_dengrate_019}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121afc6d-b5a2-4e92-a240-f6715a4eab7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## tcn demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d254d-fd22-4429-a685-18453c0ea1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation setup\n",
    "output_path = os.path.join(config['output'], \"Brazil\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "TRAINING = False  # Set to False to skip training and load an existing model\n",
    "\n",
    "if TRAINING:\n",
    "    print(\"Training the model...\")\n",
    "    # Assuming dataset_handler is already instantiated with your augmented data\n",
    "    trainingT, validationT = dataset_handler.prepare_data_TCN(x_train_a, y_train_a, x_val_a, y_val_a)\n",
    "    input_shape_dynamic = trainingT[0].shape[1:]\n",
    "    print(f\"Dynamically determined input shape from data: {input_shape_dynamic}\")\n",
    "\n",
    "    tcn = ImprovedTCNNet(shape=input_shape_dynamic)\n",
    "    history = tcn.train(training=trainingT,\n",
    "                        validation=validationT,\n",
    "                        output_path=output_path)\n",
    "else:\n",
    "    print(\"Checking for saved models...\")\n",
    "    tcn_models = glob(os.path.join(output_path, \"TCN-new-search-*.keras\"))\n",
    "    if not tcn_models:\n",
    "        print('No file with such pattern was found in the directory. Run TRAINING = True first.')\n",
    "        exit()\n",
    "    else:\n",
    "        # Load the most recent TCN model\n",
    "        tcn_models.sort(key=os.path.getmtime, reverse=True) \n",
    "        correct_shape = x_train_a.shape[1:]\n",
    "        tcn = ImprovedTCNNet(shape=correct_shape)  # Dummy shape, will be replaced by loaded model\n",
    "        tcn.load(tcn_models[0])\n",
    "        \n",
    "        print(f\"Loading model from: {tcn_models[0]}\")\n",
    "\n",
    "        # Ensure the scaler is consistent with model training\n",
    "        print(\"Checking scaler shape consistency...\")\n",
    "        y_dengue_current = validation_dataframe[['DengRate_all', 'DengRate_019']].values\n",
    "        if scaler.data_min_.shape[0] != y_dengue_current.shape[1]:\n",
    "            print(\"Warning: Scaler shape mismatch. Refitting scaler.\")\n",
    "            scaler = MinMaxScaler().fit(y_dengue_current)\n",
    "        \n",
    "        # Re-prepare the data for inference using augmented data for evaluation\n",
    "        trainingT, validationT = dataset_handler.prepare_data_TCN(x_train_a, y_train_a, x_val_a, y_val_a)\n",
    "\n",
    "        # Make predictions\n",
    "        print(\"Making predictions...\")\n",
    "        preds_tra = tcn.model.predict(trainingT[0])\n",
    "        preds_tra[preds_tra < 0] = 0\n",
    "\n",
    "        preds_val = tcn.model.predict(validationT[0])\n",
    "        preds_val[preds_val < 0] = 0\n",
    "\n",
    "        # Inverse transform predictions and ground truth if using scaling\n",
    "        try:\n",
    "            preds_val_original = scaler.inverse_transform(preds_val)\n",
    "            y_val_original = scaler.inverse_transform(validationT[1])\n",
    "            preds_tra_original = scaler.inverse_transform(preds_tra)\n",
    "            y_train_original = scaler.inverse_transform(trainingT[1])\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in inverse transformation: {e}\")\n",
    "            print(f\"Shapes: preds_val {preds_val.shape}, validationT[1] {validationT[1].shape}\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    # Collect results by department\n",
    "    results = []\n",
    "\n",
    "    for department_idx, department_name in DEP_NAMES.items():\n",
    "        department_rows_val = validation_dataframe[validation_dataframe['dep_id'] == department_idx]\n",
    "        department_rows_train = training_dataframe[training_dataframe['dep_id'] == department_idx]\n",
    "        \n",
    "        count_val = department_rows_val.shape[0]\n",
    "        count_train = department_rows_train.shape[0]\n",
    "        print(f\"{department_name}: Validation entries {count_val}, Training entries {count_train}\")\n",
    "\n",
    "        if department_rows_val.empty or department_rows_train.empty:\n",
    "            print(f\"Skipping {department_name} due to empty data.\")\n",
    "            results.append({'Department': department_name, **{k: np.nan for k in results_df.columns[1:]}})\n",
    "            continue\n",
    "\n",
    "        department_indices_val = department_rows_val.index.tolist()\n",
    "        department_indices_train = department_rows_train.index.tolist()\n",
    "\n",
    "        # In your evaluation loop for each department:\n",
    "        matching_indices_val = np.intersect1d(val_indices, department_indices_val)\n",
    "        # Filter out-of-bounds indices\n",
    "        valid_matching_indices_val = matching_indices_val[matching_indices_val < val_index_map.size]\n",
    "        original_matching_indices_val = np.unique(val_index_map[valid_matching_indices_val])\n",
    "        \n",
    "        matching_indices_train = np.intersect1d(train_indices, department_indices_train)\n",
    "        # Filter out-of-bounds indices\n",
    "        valid_matching_indices_train = matching_indices_train[matching_indices_train < train_index_map.size]\n",
    "        original_matching_indices_train = np.unique(train_index_map[valid_matching_indices_train])\n",
    "        \n",
    "        metrics = {}\n",
    "\n",
    "        # Validation Metrics\n",
    "        if original_matching_indices_val.size > 1:\n",
    "            true_dengrate_all_val = y_val_original[original_matching_indices_val, 0]\n",
    "            true_dengrate_019_val = y_val_original[original_matching_indices_val, 1]\n",
    "            predicted_dengrate_all_val = preds_val_original[original_matching_indices_val, 0]\n",
    "            predicted_dengrate_019_val = preds_val_original[original_matching_indices_val, 1]\n",
    "        \n",
    "            if len(true_dengrate_all_val) > 1 and len(predicted_dengrate_all_val) > 1:\n",
    "                metrics.update({\n",
    "                    'MAE (DengRate_all) Val': calculate_mae(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'RMSE (DengRate_all) Val': calculate_rmse(calculate_mse(true_dengrate_all_val, predicted_dengrate_all_val)),\n",
    "                    'MAPE (DengRate_all) Val': calculate_mape(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'R2 (DengRate_all) Val': calculate_r2(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'MSE (DengRate_all) Val': calculate_mse(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                    'MAE (DengRate_019) Val': calculate_mae(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                    'RMSE (DengRate_019) Val': calculate_rmse(calculate_mse(true_dengrate_019_val, predicted_dengrate_019_val)),\n",
    "                    'MAPE (DengRate_019) Val': calculate_mape(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                    'R2 (DengRate_019) Val': calculate_r2(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                    'MSE (DengRate_019) Val': calculate_mse(true_dengrate_019_val, predicted_dengrate_019_val)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Not enough validation data for {department_name} to calculate metrics.\")\n",
    "                metrics.update({k: np.nan for k in results_df.columns[1:] if 'Val' in k})\n",
    "        else:\n",
    "            print(f\"No valid validation indices for {department_name}\")\n",
    "            metrics.update({k: np.nan for k in results_df.columns[1:] if 'Val' in k})\n",
    "        \n",
    "        # Training Metrics\n",
    "        if original_matching_indices_train.size > 1:\n",
    "            true_dengrate_all_train = y_train_original[original_matching_indices_train, 0]\n",
    "            true_dengrate_019_train = y_train_original[original_matching_indices_train, 1]\n",
    "            predicted_dengrate_all_train = preds_tra_original[original_matching_indices_train, 0]\n",
    "            predicted_dengrate_019_train = preds_tra_original[original_matching_indices_train, 1]\n",
    "        \n",
    "            if len(true_dengrate_all_train) > 1 and len(predicted_dengrate_all_train) > 1:\n",
    "                metrics.update({\n",
    "                    'MAE (DengRate_all) Train': calculate_mae(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'RMSE (DengRate_all) Train': calculate_rmse(calculate_mse(true_dengrate_all_train, predicted_dengrate_all_train)),\n",
    "                    'MAPE (DengRate_all) Train': calculate_mape(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'R2 (DengRate_all) Train': calculate_r2(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'MSE (DengRate_all) Train': calculate_mse(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                    'MAE (DengRate_019) Train': calculate_mae(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                    'RMSE (DengRate_019) Train': calculate_rmse(calculate_mse(true_dengrate_019_train, predicted_dengrate_019_train)),\n",
    "                    'MAPE (DengRate_019) Train': calculate_mape(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                    'R2 (DengRate_019) Train': calculate_r2(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                    'MSE (DengRate_019) Train': calculate_mse(true_dengrate_019_train, predicted_dengrate_019_train)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Not enough training data for {department_name} to calculate metrics.\")\n",
    "                metrics.update({k: np.nan for k in results_df.columns[1:] if 'Train' in k})\n",
    "        else:\n",
    "            print(f\"No valid training indices for {department_name}\")\n",
    "            metrics.update({k: np.nan for k in results_df.columns[1:] if 'Train' in k})\n",
    "\n",
    "        # Append results for this department\n",
    "        results.append({\n",
    "            'Department': department_name,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame and save metrics\n",
    "    results_df = pd.DataFrame(results)\n",
    "    today = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    out_csv = os.path.join(config['metrics'], \"Brazil\",\n",
    "                           f'TCN_new_model_search_{today}.csv')\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    results_df.to_csv(out_csv, index=False)\n",
    "    print(f\"Results saved to {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec520ff-3f9f-42bf-bc07-39e7f7b1790a",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1f11b88a-453b-40e1-a07f-170aae92286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Input, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2b9f50d-3511-4d57-bd7b-51afc2b4f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming x_train originally has 42 features and you want 39\n",
    "trainL, valL = dataset_handler.prepare_data_LSTM(x_train[:,:,3:], y_train, x_val[:,:,3:], y_val)  # Adjust slice to get 39 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa8f2c3a-06f2-4bf1-b050-3a85f6713f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Input Shape: (3888, 12, 42)\n",
      "Validation Input Shape: (648, 12, 42)\n",
      "Training Input Sliced Shape: (3888, 12, 40)\n",
      "Validation Input Sliced Shape: (648, 12, 40)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Input Shape:\", x_train.shape)\n",
    "print(\"Validation Input Shape:\", x_val.shape)\n",
    "print(\"Training Input Sliced Shape:\", x_train[:,:,2:].shape)\n",
    "print(\"Validation Input Sliced Shape:\", x_val[:,:,2:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0613f4c-486b-4c08-8b8c-3062aed0dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, MeanSquaredError\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "356d430f-f939-403a-ad27-c3d412229c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings for LSTM\n",
    "LSTM_SETTINGS = {\n",
    "    'EPOCHS': 200,\n",
    "    'LEARNING_RATE': 0.0001,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'OPTIMIZER': 'rmsprop',  # Default to 'rmsprop', can be switched to 'adam'\n",
    "    'LOSS': 'mae',\n",
    "    'EVALUATION_METRIC': ['mse', 'mae'],\n",
    "    'EARLY_STOPPING_PATIENCE': 24,\n",
    "    'DROPOUT_RATE': 0.3  # Adjusted dropout rate for better regularization\n",
    "}\n",
    "\n",
    "# Utility functions for metrics calculation\n",
    "def calculate_mae(true_values, predicted_values):\n",
    "    return mean_absolute_error(true_values, predicted_values)\n",
    "\n",
    "def calculate_mse(true_values, predicted_values):\n",
    "    return mean_squared_error(true_values, predicted_values)\n",
    "\n",
    "def calculate_rmse(mse):\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def calculate_mape(true_values, predicted_values):\n",
    "    mask = true_values > 0  # Avoid division by zero\n",
    "    return np.mean(np.abs((true_values[mask] - predicted_values[mask]) / true_values[mask])) * 100 if mask.any() else 0\n",
    "\n",
    "def calculate_r2(true_values, predicted_values):\n",
    "    return r2_score(true_values, predicted_values)\n",
    "\n",
    "def calculate_nrmse(true_values, predicted_values):\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "    return rmse / (true_values.max() - true_values.min()) if true_values.max() != true_values.min() else 0\n",
    "\n",
    "def discretize_to_binary(values, threshold=0.5):\n",
    "    return np.where(values > threshold, 1, 0)\n",
    "\n",
    "def plot_confusion_matrix(true_values, predicted_values, department_name, metric_type=\"All\"):\n",
    "    cm = confusion_matrix(true_values, predicted_values)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "    ax.set_title(f'Confusion Matrix: {department_name} - {metric_type}')\n",
    "    plt.show()\n",
    "\n",
    "# Custom model loading function\n",
    "def custom_load_model(path):\n",
    "    return tf.keras.models.load_model(\n",
    "        path,\n",
    "        custom_objects={\n",
    "            'mae': MeanAbsoluteError(),\n",
    "            'mse': MeanSquaredError()\n",
    "        },\n",
    "        compile=True\n",
    "    )\n",
    "\n",
    "# LSTM Model Class\n",
    "class LSTMNet:\n",
    "    def __init__(self, shape, output_units=2):\n",
    "        self.shape = shape\n",
    "        self.epochs = LSTM_SETTINGS['EPOCHS']\n",
    "        self.lr = LSTM_SETTINGS['LEARNING_RATE']\n",
    "        self.batch_size = LSTM_SETTINGS['BATCH_SIZE']\n",
    "        self.loss = LSTM_SETTINGS['LOSS']\n",
    "        self.eval_metric = LSTM_SETTINGS['EVALUATION_METRIC']\n",
    "        self.early_stopping_rounds = LSTM_SETTINGS['EARLY_STOPPING_PATIENCE']\n",
    "        self.dropout_rate = LSTM_SETTINGS['DROPOUT_RATE']\n",
    "        \n",
    "        # Optimizer selection with fallback\n",
    "        optimizer_name = LSTM_SETTINGS.get('OPTIMIZER', 'adam')\n",
    "        if optimizer_name == 'adam':\n",
    "            self.optimizer = Adam(learning_rate=self.lr)\n",
    "        elif optimizer_name == 'rmsprop':\n",
    "            self.optimizer = RMSprop(learning_rate=self.lr)\n",
    "        else:\n",
    "            self.optimizer = Adam(learning_rate=self.lr)  # Default to Adam if unknown\n",
    "        \n",
    "        self.model = self.__build()\n",
    "\n",
    "    def __build(self):\n",
    "        \"\"\"Build the LSTM model architecture.\"\"\"\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=self.shape),\n",
    "            layers.LSTM(60, return_sequences=True, dropout=self.dropout_rate, recurrent_dropout=0.2),\n",
    "            layers.LSTM(20, dropout=self.dropout_rate, recurrent_dropout=0.2),\n",
    "            layers.Dense(2, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.eval_metric)\n",
    "        return model\n",
    "\n",
    "    def load(self, model_path):\n",
    "        \"\"\"Load a pre-trained model from the specified path.\"\"\"\n",
    "        self.model = custom_load_model(model_path)\n",
    "        print(f\"Model loaded successfully from {model_path}\")\n",
    "\n",
    "    def train(self, training, validation, output_path):\n",
    "        \"\"\"Train the LSTM model with early stopping and learning rate reduction.\"\"\"\n",
    "        es = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=0.001,  # Small improvement threshold\n",
    "            patience=self.early_stopping_rounds,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(f\"Training Data Shapes: Input {training[0].shape}, Output {training[1].shape}\")\n",
    "        print(f\"Validation Data Shapes: Input {validation[0].shape}, Output {validation[1].shape}\")\n",
    "\n",
    "        history = self.model.fit(\n",
    "            x=training[0],\n",
    "            y=training[1],\n",
    "            validation_data=(validation[0], validation[1]),\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            callbacks=[es, lr_scheduler],\n",
    "            shuffle=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.title('LSTM Model Loss Curve')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "        today = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "        save_path = os.path.join(output_path, f'LSTM-search-{today}.h5')\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        self.model.save(save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6acddd1-af7a-4ac7-ac83-13e882a08da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for saved models...\n",
      "Model loaded successfully from C:\\Users\\amanp\\Desktop\\MINOR\\projj\\code\\saved_models\\Brazil\\LSTM-search-26-11-2024-00-42-16.h5\n",
      "Loading model from: C:\\Users\\amanp\\Desktop\\MINOR\\projj\\code\\saved_models\\Brazil\\LSTM-search-26-11-2024-00-42-16.h5\n",
      "Making predictions...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 40 and 39 for '{{node sequential_2_1/lstm_4_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_2_1/lstm_4_1/strided_slice_2, sequential_2_1/lstm_4_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [32,40], [39,240].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(32, 40), dtype=float32)\n  • states=('tf.Tensor(shape=(32, 60), dtype=float32)', 'tf.Tensor(shape=(32, 60), dtype=float32)')\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m preds_tra \u001b[38;5;241m=\u001b[39m \u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m preds_tra[preds_tra \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     30\u001b[0m preds_val \u001b[38;5;241m=\u001b[39m lstm\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(valL[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 40 and 39 for '{{node sequential_2_1/lstm_4_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_2_1/lstm_4_1/strided_slice_2, sequential_2_1/lstm_4_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [32,40], [39,240].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(32, 40), dtype=float32)\n  • states=('tf.Tensor(shape=(32, 60), dtype=float32)', 'tf.Tensor(shape=(32, 60), dtype=float32)')\n  • training=False"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training and Evaluation Setup\n",
    "output_path = os.path.join(config['output'], \"Brazil\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "TRAINING = False\n",
    "\n",
    "# Initialize LSTM model\n",
    "lstm = LSTMNet(trainingL[0].shape[1:])\n",
    "\n",
    "if TRAINING:\n",
    "    print(\"Training the model...\")\n",
    "    lstm.train(trainingL, validationL, output_path=output_path)\n",
    "else:\n",
    "    print(\"Checking for saved models...\")\n",
    "    lstm_models = glob(os.path.join(config['output'], \"Brazil\", \"LSTM-search-*.h5\"))\n",
    "    if not lstm_models:\n",
    "        print('No file with such pattern was found in the directory. Run TRAINING = True first.')\n",
    "        exit()\n",
    "    else:\n",
    "        lstm.load(lstm_models[-1])\n",
    "        print(f\"Loading model from: {lstm_models[-1]}\")\n",
    "\n",
    "    # Prepare data for inference\n",
    "    trainL, valL = dataset_handler.prepare_data_LSTM(x_train[:,:,2:], y_train, x_val[:,:,2:], y_val)\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    preds_tra = lstm.model.predict(trainL[0])\n",
    "    preds_tra[preds_tra < 0] = 0\n",
    "    preds_val = lstm.model.predict(valL[0])\n",
    "    preds_val[preds_val < 0] = 0\n",
    "\n",
    "    # Inverse transform predictions and ground truth\n",
    "    preds_val_original = scaler.inverse_transform(preds_val)\n",
    "    y_val_original = scaler.inverse_transform(valL[1])\n",
    "    preds_tra_original = scaler.inverse_transform(preds_tra)\n",
    "    y_train_original = scaler.inverse_transform(trainL[1])\n",
    "\n",
    "    # Index mappings\n",
    "    y_val_indices_df = pd.DataFrame(val_indices, columns=['actual_index'])\n",
    "    y_train_indices_df = pd.DataFrame(train_indices, columns=['actual_index'])\n",
    "\n",
    "    # Define metric columns\n",
    "    metric_columns = [\n",
    "        'Department',\n",
    "        'MAE (DengRate_all) Val', 'RMSE (DengRate_all) Val', 'MAPE (DengRate_all) Val', 'R2 (DengRate_all) Val', 'MSE (DengRate_all) Val',\n",
    "        'MAE (DengRate_019) Val', 'RMSE (DengRate_019) Val', 'MAPE (DengRate_019) Val', 'R2 (DengRate_019) Val', 'MSE (DengRate_019) Val',\n",
    "        'MAE (DengRate_all) Train', 'RMSE (DengRate_all) Train', 'MAPE (DengRate_all) Train', 'R2 (DengRate_all) Train', 'MSE (DengRate_all) Train',\n",
    "        'MAE (DengRate_019) Train', 'RMSE (DengRate_019) Train', 'MAPE (DengRate_019) Train', 'R2 (DengRate_019) Train', 'MSE (DengRate_019) Train'\n",
    "    ]\n",
    "\n",
    "    # Collect results by department\n",
    "    results = []\n",
    "\n",
    "    for department_idx, department_name in DEP_NAMES.items():\n",
    "        department_rows_val = validation_dataframe[validation_dataframe['dep_id'] == department_idx]\n",
    "        department_rows_train = training_dataframe[training_dataframe['dep_id'] == department_idx]\n",
    "\n",
    "        count_val = department_rows_val.shape[0]\n",
    "        count_train = department_rows_train.shape[0]\n",
    "        print(f\"{department_name}: Validation entries {count_val}, Training entries {count_train}\")\n",
    "\n",
    "        if department_rows_val.empty or department_rows_train.empty:\n",
    "            print(f\"Skipping {department_name} due to empty data.\")\n",
    "            results.append({'Department': department_name, **{k: np.nan for k in metric_columns[1:]}})\n",
    "            continue\n",
    "\n",
    "        department_indices_val = department_rows_val.index.tolist()\n",
    "        department_indices_train = department_rows_train.index.tolist()\n",
    "\n",
    "        matching_indices_val = y_val_indices_df[y_val_indices_df['actual_index'].isin(department_indices_val)].index\n",
    "        matching_indices_train = y_train_indices_df[y_train_indices_df['actual_index'].isin(department_indices_train)].index\n",
    "\n",
    "        if matching_indices_val.empty or matching_indices_train.empty:\n",
    "            print(f\"No matching indices for {department_name}\")\n",
    "            results.append({'Department': department_name, **{k: np.nan for k in metric_columns[1:]}})\n",
    "            continue\n",
    "\n",
    "        # Validation metrics\n",
    "        metrics = {}\n",
    "        if len(matching_indices_val) > 1:\n",
    "            true_dengrate_all_val = y_val_original[matching_indices_val, 0]\n",
    "            true_dengrate_019_val = y_val_original[matching_indices_val, 1]\n",
    "            predicted_dengrate_all_val = preds_val_original[matching_indices_val, 0]\n",
    "            predicted_dengrate_019_val = preds_val_original[matching_indices_val, 1]\n",
    "\n",
    "            metrics.update({\n",
    "                'MAE (DengRate_all) Val': calculate_mae(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                'RMSE (DengRate_all) Val': calculate_rmse(calculate_mse(true_dengrate_all_val, predicted_dengrate_all_val)),\n",
    "                'MAPE (DengRate_all) Val': calculate_mape(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                'R2 (DengRate_all) Val': calculate_r2(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                'MSE (DengRate_all) Val': calculate_mse(true_dengrate_all_val, predicted_dengrate_all_val),\n",
    "                'MAE (DengRate_019) Val': calculate_mae(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                'RMSE (DengRate_019) Val': calculate_rmse(calculate_mse(true_dengrate_019_val, predicted_dengrate_019_val)),\n",
    "                'MAPE (DengRate_019) Val': calculate_mape(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                'R2 (DengRate_019) Val': calculate_r2(true_dengrate_019_val, predicted_dengrate_019_val),\n",
    "                'MSE (DengRate_019) Val': calculate_mse(true_dengrate_019_val, predicted_dengrate_019_val)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Not enough validation data for {department_name} to calculate metrics.\")\n",
    "            metrics.update({k: np.nan for k in metric_columns[1:] if 'Val' in k})\n",
    "\n",
    "        # Training metrics\n",
    "        if len(matching_indices_train) > 1:\n",
    "            true_dengrate_all_train = y_train_original[matching_indices_train, 0]\n",
    "            true_dengrate_019_train = y_train_original[matching_indices_train, 1]\n",
    "            predicted_dengrate_all_train = preds_tra_original[matching_indices_train, 0]\n",
    "            predicted_dengrate_019_train = preds_tra_original[matching_indices_train, 1]\n",
    "\n",
    "            metrics.update({\n",
    "                'MAE (DengRate_all) Train': calculate_mae(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                'RMSE (DengRate_all) Train': calculate_rmse(calculate_mse(true_dengrate_all_train, predicted_dengrate_all_train)),\n",
    "                'MAPE (DengRate_all) Train': calculate_mape(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                'R2 (DengRate_all) Train': calculate_r2(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                'MSE (DengRate_all) Train': calculate_mse(true_dengrate_all_train, predicted_dengrate_all_train),\n",
    "                'MAE (DengRate_019) Train': calculate_mae(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                'RMSE (DengRate_019) Train': calculate_rmse(calculate_mse(true_dengrate_019_train, predicted_dengrate_019_train)),\n",
    "                'MAPE (DengRate_019) Train': calculate_mape(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                'R2 (DengRate_019) Train': calculate_r2(true_dengrate_019_train, predicted_dengrate_019_train),\n",
    "                'MSE (DengRate_019) Train': calculate_mse(true_dengrate_019_train, predicted_dengrate_019_train)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Not enough training data for {department_name} to calculate metrics.\")\n",
    "            metrics.update({k: np.nan for k in metric_columns[1:] if 'Train' in k})\n",
    "\n",
    "        # Append results\n",
    "        results.append({'Department': department_name, **metrics})\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame(results, columns=metric_columns)\n",
    "    today = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    output_path = os.path.join(config['metrics'], \"Brazil\", f'LSTM_Model_search_{today}.csv')\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e7b50a51-2ae5-47b6-8986-8b64f1ea3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_val_original shape: (1944, 2)\n",
      "preds_val_original shape: (1944, 2)\n",
      "matching_indices_val: [5160 5161 5162 5163 5164 5165 5166 5167 5168 5169 5170 5171 5172 5173\n",
      " 5174 5175 5176 5177 5178 5179 5180 5181 5182 5183]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_val_original shape:\", y_val_original.shape)\n",
    "print(\"preds_val_original shape:\", preds_val_original.shape)\n",
    "print(\"matching_indices_val:\", matching_indices_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "10e3dcd7-727d-41d9-9834-a6d6c80b86a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE DengRate_all: 0.0005212383576788037, RMSE DengRate_all: 0.022830645143727405, MAE DengRate_all: 0.011843019487347254, MAPE DengRate_all: 99880992500.28503, R2 DengRate_all: 0.8170969227494213\n",
      "MSE DengRate_019: 0.0003541651272817527, RMSE DengRate_019: 0.018819275418616752, MAE DengRate_019: 0.012112610275227385, MAPE DengRate_019: 85262614331.33304, R2 DengRate_019: 0.8304722141414287\n"
     ]
    }
   ],
   "source": [
    "mse_dengrate_all = mean_squared_error(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "rmse_dengrate_all = np.sqrt(mse_dengrate_all)\n",
    "mae_dengrate_all = mean_absolute_error(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "mape_dengrate_all = mean_absolute_percentage_error(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "r2_dengrate_all = r2_score(y_val_original[:, 0], preds_val_original[:, 0])\n",
    "\n",
    "# For the second output (DengRate_019):\n",
    "mse_dengrate_019 = mean_squared_error(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "rmse_dengrate_019 = np.sqrt(mse_dengrate_019)\n",
    "mae_dengrate_019 = mean_absolute_error(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "mape_dengrate_019 = mean_absolute_percentage_error(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "r2_dengrate_019 = r2_score(y_val_original[:, 1], preds_val_original[:, 1])\n",
    "\n",
    "# Print the results\n",
    "print(f\"MSE DengRate_all: {mse_dengrate_all}, RMSE DengRate_all: {rmse_dengrate_all}, MAE DengRate_all: {mae_dengrate_all}, MAPE DengRate_all: {mape_dengrate_all}, R2 DengRate_all: {r2_dengrate_all}\")\n",
    "print(f\"MSE DengRate_019: {mse_dengrate_019}, RMSE DengRate_019: {rmse_dengrate_019}, MAE DengRate_019: {mae_dengrate_019}, MAPE DengRate_019: {mape_dengrate_019}, R2 DengRate_019: {r2_dengrate_019}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1c33c-b6ae-4d58-874e-f70affe20e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
